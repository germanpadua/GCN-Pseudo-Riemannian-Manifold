Experiment with num_layers=2, weight_decay=0, dropout=0, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.8171 train_acc: 0.6632 train_f1: 0.6632 time: 0.0098s
INFO:root:Epoch: 0050 val_loss: 0.8674 val_acc: 0.6514 val_f1: 0.6514
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.8274s
INFO:root:Val set results: val_loss: 0.8674 val_acc: 0.6514 val_f1: 0.6514
INFO:root:Test set results: test_loss: 0.9121 test_acc: 0.6130 test_f1: 0.6130
INFO:root:Saved model in /content/logs/nc/2024_7_1/258

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.9446 train_acc: 0.6046 train_f1: 0.6046 time: 0.0123s
INFO:root:Epoch: 0050 val_loss: 0.9710 val_acc: 0.5941 val_f1: 0.5941
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.3304s
INFO:root:Val set results: val_loss: 0.9972 val_acc: 0.6080 val_f1: 0.6080
INFO:root:Test set results: test_loss: 1.0450 test_acc: 0.5858 test_f1: 0.5858
INFO:root:Saved model in /content/logs/nc/2024_7_1/259

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.9413 train_acc: 0.6004 train_f1: 0.6004 time: 0.0088s
INFO:root:Epoch: 0050 val_loss: 0.9675 val_acc: 0.5963 val_f1: 0.5963
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7162s
INFO:root:Val set results: val_loss: 0.9950 val_acc: 0.6084 val_f1: 0.6084
INFO:root:Test set results: test_loss: 1.0437 test_acc: 0.5816 test_f1: 0.5816
INFO:root:Saved model in /content/logs/nc/2024_7_1/260

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0.2, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.8426 train_acc: 0.6611 train_f1: 0.6611 time: 0.0134s
INFO:root:Epoch: 0050 val_loss: 0.8648 val_acc: 0.6519 val_f1: 0.6519
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.5438s
INFO:root:Val set results: val_loss: 0.8648 val_acc: 0.6519 val_f1: 0.6519
INFO:root:Test set results: test_loss: 0.9089 test_acc: 0.6151 test_f1: 0.6151
INFO:root:Saved model in /content/logs/nc/2024_7_1/261

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0.2, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.9785 train_acc: 0.5858 train_f1: 0.5858 time: 0.0087s
INFO:root:Epoch: 0050 val_loss: 0.9801 val_acc: 0.5878 val_f1: 0.5878
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7019s
INFO:root:Val set results: val_loss: 0.9939 val_acc: 0.6044 val_f1: 0.6044
INFO:root:Test set results: test_loss: 1.0422 test_acc: 0.5858 test_f1: 0.5858
INFO:root:Saved model in /content/logs/nc/2024_7_1/262

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0.2, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.9763 train_acc: 0.5816 train_f1: 0.5816 time: 0.0091s
INFO:root:Epoch: 0050 val_loss: 0.9766 val_acc: 0.5927 val_f1: 0.5927
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.5269s
INFO:root:Val set results: val_loss: 0.9927 val_acc: 0.6053 val_f1: 0.6053
INFO:root:Test set results: test_loss: 1.0423 test_acc: 0.5774 test_f1: 0.5774
INFO:root:Saved model in /content/logs/nc/2024_7_1/263

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0.5, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.9400 train_acc: 0.6109 train_f1: 0.6109 time: 0.0094s
INFO:root:Epoch: 0050 val_loss: 0.8899 val_acc: 0.6443 val_f1: 0.6443
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.8048s
INFO:root:Val set results: val_loss: 0.8926 val_acc: 0.6470 val_f1: 0.6470
INFO:root:Test set results: test_loss: 0.9391 test_acc: 0.6151 test_f1: 0.6151
INFO:root:Saved model in /content/logs/nc/2024_7_1/264

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0.5, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 1.0413 train_acc: 0.5795 train_f1: 0.5795 time: 0.0093s
INFO:root:Epoch: 0050 val_loss: 0.9775 val_acc: 0.5999 val_f1: 0.5999
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.4234s
INFO:root:Val set results: val_loss: 1.0162 val_acc: 0.6066 val_f1: 0.6066
INFO:root:Test set results: test_loss: 1.0589 test_acc: 0.5816 test_f1: 0.5816
INFO:root:Saved model in /content/logs/nc/2024_7_1/265

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0.5, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 1.0372 train_acc: 0.5858 train_f1: 0.5858 time: 0.0089s
INFO:root:Epoch: 0050 val_loss: 0.9739 val_acc: 0.6013 val_f1: 0.6013
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.6901s
INFO:root:Val set results: val_loss: 1.0184 val_acc: 0.6071 val_f1: 0.6071
INFO:root:Test set results: test_loss: 1.0617 test_acc: 0.5858 test_f1: 0.5858
INFO:root:Saved model in /content/logs/nc/2024_7_1/266

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.7979 train_acc: 0.6590 train_f1: 0.6590 time: 0.0091s
INFO:root:Epoch: 0050 val_loss: 0.8472 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.5017s
INFO:root:Val set results: val_loss: 0.8523 val_acc: 0.6591 val_f1: 0.6591
INFO:root:Test set results: test_loss: 0.8885 test_acc: 0.6172 test_f1: 0.6172
INFO:root:Saved model in /content/logs/nc/2024_7_1/267

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.9509 train_acc: 0.5983 train_f1: 0.5983 time: 0.0088s
INFO:root:Epoch: 0050 val_loss: 0.9740 val_acc: 0.5909 val_f1: 0.5909
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.6444s
INFO:root:Val set results: val_loss: 1.0008 val_acc: 0.6084 val_f1: 0.6084
INFO:root:Test set results: test_loss: 1.0465 test_acc: 0.5837 test_f1: 0.5837
INFO:root:Saved model in /content/logs/nc/2024_7_1/268

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.9473 train_acc: 0.5983 train_f1: 0.5983 time: 0.0090s
INFO:root:Epoch: 0050 val_loss: 0.9706 val_acc: 0.5923 val_f1: 0.5923
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.2822s
INFO:root:Val set results: val_loss: 0.9989 val_acc: 0.6098 val_f1: 0.6098
INFO:root:Test set results: test_loss: 1.0453 test_acc: 0.5858 test_f1: 0.5858
INFO:root:Saved model in /content/logs/nc/2024_7_1/269

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0.2, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.8455 train_acc: 0.6611 train_f1: 0.6611 time: 0.0087s
INFO:root:Epoch: 0050 val_loss: 0.8576 val_acc: 0.6501 val_f1: 0.6501
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7587s
INFO:root:Val set results: val_loss: 0.8576 val_acc: 0.6501 val_f1: 0.6501
INFO:root:Test set results: test_loss: 0.8965 test_acc: 0.6130 test_f1: 0.6130
INFO:root:Saved model in /content/logs/nc/2024_7_1/270

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0.2, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.9843 train_acc: 0.5900 train_f1: 0.5900 time: 0.0093s
INFO:root:Epoch: 0050 val_loss: 0.9844 val_acc: 0.5860 val_f1: 0.5860
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.3063s
INFO:root:Val set results: val_loss: 0.9968 val_acc: 0.6026 val_f1: 0.6026
INFO:root:Test set results: test_loss: 1.0434 test_acc: 0.5858 test_f1: 0.5858
INFO:root:Saved model in /content/logs/nc/2024_7_1/271

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0.2, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.9821 train_acc: 0.5858 train_f1: 0.5858 time: 0.0091s
INFO:root:Epoch: 0050 val_loss: 0.9810 val_acc: 0.5896 val_f1: 0.5896
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7435s
INFO:root:Val set results: val_loss: 0.9949 val_acc: 0.6022 val_f1: 0.6022
INFO:root:Test set results: test_loss: 1.0425 test_acc: 0.5858 test_f1: 0.5858
INFO:root:Saved model in /content/logs/nc/2024_7_1/272

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0.5, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.9469 train_acc: 0.6109 train_f1: 0.6109 time: 0.0094s
INFO:root:Epoch: 0050 val_loss: 0.8939 val_acc: 0.6353 val_f1: 0.6353
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.3657s
INFO:root:Val set results: val_loss: 0.9047 val_acc: 0.6398 val_f1: 0.6398
INFO:root:Test set results: test_loss: 0.9455 test_acc: 0.6151 test_f1: 0.6151
INFO:root:Saved model in /content/logs/nc/2024_7_1/273

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0.5, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 1.0463 train_acc: 0.5753 train_f1: 0.5753 time: 0.0086s
INFO:root:Epoch: 0050 val_loss: 0.9831 val_acc: 0.6030 val_f1: 0.6030
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.6650s
INFO:root:Val set results: val_loss: 1.0205 val_acc: 0.6075 val_f1: 0.6075
INFO:root:Test set results: test_loss: 1.0613 test_acc: 0.5774 test_f1: 0.5774
INFO:root:Saved model in /content/logs/nc/2024_7_1/274

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0.5, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 2052
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 1.0419 train_acc: 0.5774 train_f1: 0.5774 time: 0.0090s
INFO:root:Epoch: 0050 val_loss: 0.9796 val_acc: 0.6013 val_f1: 0.6013
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.2401s
INFO:root:Val set results: val_loss: 1.0206 val_acc: 0.6071 val_f1: 0.6071
INFO:root:Test set results: test_loss: 1.0620 test_acc: 0.5816 test_f1: 0.5816
INFO:root:Saved model in /content/logs/nc/2024_7_1/275

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.5724 train_acc: 0.7866 train_f1: 0.7866 time: 0.0113s
INFO:root:Epoch: 0050 val_loss: 0.6770 val_acc: 0.7496 val_f1: 0.7496
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.9980s
INFO:root:Val set results: val_loss: 0.6770 val_acc: 0.7496 val_f1: 0.7496
INFO:root:Test set results: test_loss: 0.7084 test_acc: 0.7385 test_f1: 0.7385
INFO:root:Saved model in /content/logs/nc/2024_7_1/276

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.8187 train_acc: 0.6506 train_f1: 0.6506 time: 0.0106s
INFO:root:Epoch: 0050 val_loss: 0.8832 val_acc: 0.6353 val_f1: 0.6353
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.1779s
INFO:root:Val set results: val_loss: 0.8832 val_acc: 0.6353 val_f1: 0.6353
INFO:root:Test set results: test_loss: 0.9232 test_acc: 0.6025 test_f1: 0.6025
INFO:root:Saved model in /content/logs/nc/2024_7_1/277

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.8054 train_acc: 0.6611 train_f1: 0.6611 time: 0.0119s
INFO:root:Epoch: 0050 val_loss: 0.8658 val_acc: 0.6532 val_f1: 0.6532
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.8664s
INFO:root:Val set results: val_loss: 0.8658 val_acc: 0.6532 val_f1: 0.6532
INFO:root:Test set results: test_loss: 0.9129 test_acc: 0.6130 test_f1: 0.6130
INFO:root:Saved model in /content/logs/nc/2024_7_1/278

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0.2, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.6225 train_acc: 0.7510 train_f1: 0.7510 time: 0.0113s
INFO:root:Epoch: 0050 val_loss: 0.7024 val_acc: 0.7397 val_f1: 0.7397
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.2997s
INFO:root:Val set results: val_loss: 0.6935 val_acc: 0.7424 val_f1: 0.7424
INFO:root:Test set results: test_loss: 0.7470 test_acc: 0.7218 test_f1: 0.7218
INFO:root:Saved model in /content/logs/nc/2024_7_1/279

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0.2, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.8438 train_acc: 0.6506 train_f1: 0.6506 time: 0.0144s
INFO:root:Epoch: 0050 val_loss: 0.8866 val_acc: 0.6304 val_f1: 0.6304
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.8278s
INFO:root:Val set results: val_loss: 0.8811 val_acc: 0.6398 val_f1: 0.6398
INFO:root:Test set results: test_loss: 0.9265 test_acc: 0.5941 test_f1: 0.5941
INFO:root:Saved model in /content/logs/nc/2024_7_1/280

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0.2, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.8271 train_acc: 0.6590 train_f1: 0.6590 time: 0.0113s
INFO:root:Epoch: 0050 val_loss: 0.8658 val_acc: 0.6528 val_f1: 0.6528
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.0631s
INFO:root:Val set results: val_loss: 0.8607 val_acc: 0.6599 val_f1: 0.6599
INFO:root:Test set results: test_loss: 0.9150 test_acc: 0.6297 test_f1: 0.6297
INFO:root:Saved model in /content/logs/nc/2024_7_1/281

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0.5, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.7872 train_acc: 0.6653 train_f1: 0.6653 time: 0.0108s
INFO:root:Epoch: 0050 val_loss: 0.7874 val_acc: 0.6613 val_f1: 0.6613
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.9389s
INFO:root:Val set results: val_loss: 0.7628 val_acc: 0.7124 val_f1: 0.7124
INFO:root:Test set results: test_loss: 0.7997 test_acc: 0.6778 test_f1: 0.6778
INFO:root:Saved model in /content/logs/nc/2024_7_1/282

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0.5, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.9544 train_acc: 0.6088 train_f1: 0.6088 time: 0.0108s
INFO:root:Epoch: 0050 val_loss: 0.9272 val_acc: 0.6165 val_f1: 0.6165
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.8956s
INFO:root:Val set results: val_loss: 0.9388 val_acc: 0.6349 val_f1: 0.6349
INFO:root:Test set results: test_loss: 0.9868 test_acc: 0.6297 test_f1: 0.6297
INFO:root:Saved model in /content/logs/nc/2024_7_1/283

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0.5, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.9559 train_acc: 0.6025 train_f1: 0.6025 time: 0.0113s
INFO:root:Epoch: 0050 val_loss: 0.8931 val_acc: 0.6219 val_f1: 0.6219
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.8529s
INFO:root:Val set results: val_loss: 0.9304 val_acc: 0.6407 val_f1: 0.6407
INFO:root:Test set results: test_loss: 0.9849 test_acc: 0.5900 test_f1: 0.5900
INFO:root:Saved model in /content/logs/nc/2024_7_1/284

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.5859 train_acc: 0.7782 train_f1: 0.7782 time: 0.0127s
INFO:root:Epoch: 0050 val_loss: 0.6860 val_acc: 0.7379 val_f1: 0.7379
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.0530s
INFO:root:Val set results: val_loss: 0.6983 val_acc: 0.7424 val_f1: 0.7424
INFO:root:Test set results: test_loss: 0.7129 test_acc: 0.7322 test_f1: 0.7322
INFO:root:Saved model in /content/logs/nc/2024_7_1/285

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.8604 train_acc: 0.6234 train_f1: 0.6234 time: 0.0107s
INFO:root:Epoch: 0050 val_loss: 0.9141 val_acc: 0.6147 val_f1: 0.6147
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.8287s
INFO:root:Val set results: val_loss: 0.9570 val_acc: 0.6246 val_f1: 0.6246
INFO:root:Test set results: test_loss: 1.0128 test_acc: 0.6192 test_f1: 0.6192
INFO:root:Saved model in /content/logs/nc/2024_7_1/286

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.8398 train_acc: 0.6192 train_f1: 0.6192 time: 0.0099s
INFO:root:Epoch: 0050 val_loss: 0.8865 val_acc: 0.6241 val_f1: 0.6241
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.8233s
INFO:root:Val set results: val_loss: 0.9515 val_acc: 0.6286 val_f1: 0.6286
INFO:root:Test set results: test_loss: 1.0165 test_acc: 0.6213 test_f1: 0.6213
INFO:root:Saved model in /content/logs/nc/2024_7_1/287

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0.2, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.6430 train_acc: 0.7531 train_f1: 0.7531 time: 0.0110s
INFO:root:Epoch: 0050 val_loss: 0.7245 val_acc: 0.7177 val_f1: 0.7177
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.9978s
INFO:root:Val set results: val_loss: 0.7225 val_acc: 0.7267 val_f1: 0.7267
INFO:root:Test set results: test_loss: 0.7531 test_acc: 0.6946 test_f1: 0.6946
INFO:root:Saved model in /content/logs/nc/2024_7_1/288

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0.2, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.8890 train_acc: 0.6276 train_f1: 0.6276 time: 0.0124s
INFO:root:Epoch: 0050 val_loss: 0.9153 val_acc: 0.6228 val_f1: 0.6228
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.8724s
INFO:root:Val set results: val_loss: 0.9370 val_acc: 0.6272 val_f1: 0.6272
INFO:root:Test set results: test_loss: 0.9881 test_acc: 0.6151 test_f1: 0.6151
INFO:root:Saved model in /content/logs/nc/2024_7_1/289

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0.2, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.8610 train_acc: 0.6318 train_f1: 0.6318 time: 0.0104s
INFO:root:Epoch: 0050 val_loss: 0.8886 val_acc: 0.6286 val_f1: 0.6286
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.8364s
INFO:root:Val set results: val_loss: 0.9579 val_acc: 0.6340 val_f1: 0.6340
INFO:root:Test set results: test_loss: 1.0190 test_acc: 0.6046 test_f1: 0.6046
INFO:root:Saved model in /content/logs/nc/2024_7_1/290

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0.5, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.8145 train_acc: 0.6820 train_f1: 0.6820 time: 0.0109s
INFO:root:Epoch: 0050 val_loss: 0.7909 val_acc: 0.6985 val_f1: 0.6985
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.9280s
INFO:root:Val set results: val_loss: 0.7809 val_acc: 0.7352 val_f1: 0.7352
INFO:root:Test set results: test_loss: 0.8113 test_acc: 0.7008 test_f1: 0.7008
INFO:root:Saved model in /content/logs/nc/2024_7_1/291

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0.5, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.9787 train_acc: 0.5941 train_f1: 0.5941 time: 0.0154s
INFO:root:Epoch: 0050 val_loss: 0.9472 val_acc: 0.6089 val_f1: 0.6089
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.9087s
INFO:root:Val set results: val_loss: 0.9579 val_acc: 0.6344 val_f1: 0.6344
INFO:root:Test set results: test_loss: 1.0112 test_acc: 0.5941 test_f1: 0.5941
INFO:root:Saved model in /content/logs/nc/2024_7_1/292

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0.5, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3188
INFO:root:Number of features: 11
INFO:root:Number of classes: 4
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=11, output_dim=128
        (linear): Linear(in_features=11, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=4
      (linear): Linear(in_features=128, out_features=4, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 18564
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.9751 train_acc: 0.5879 train_f1: 0.5879 time: 0.0111s
INFO:root:Epoch: 0050 val_loss: 0.9260 val_acc: 0.6129 val_f1: 0.6129
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.5860s
INFO:root:Val set results: val_loss: 0.9427 val_acc: 0.6434 val_f1: 0.6434
INFO:root:Test set results: test_loss: 0.9930 test_acc: 0.6046 test_f1: 0.6046
INFO:root:Saved model in /content/logs/nc/2024_7_1/293

================================================================================
