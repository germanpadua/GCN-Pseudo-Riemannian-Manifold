Experiment with num_layers=2, weight_decay=0, dropout=0, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0000 train_acc: 1.0000 train_f1: 1.0000 time: 0.0088s
INFO:root:Epoch: 0050 val_loss: 2.9989 val_acc: 0.6240 val_f1: 0.6240
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.6205s
INFO:root:Val set results: val_loss: 1.1185 val_acc: 0.6740 val_f1: 0.6740
INFO:root:Test set results: test_loss: 1.1284 test_acc: 0.6700 test_f1: 0.6700
INFO:root:Saved model in /content/logs/nc/2024_7_1/150

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0001 train_acc: 1.0000 train_f1: 1.0000 time: 0.0097s
INFO:root:Epoch: 0050 val_loss: 2.6026 val_acc: 0.6240 val_f1: 0.6240
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.3062s
INFO:root:Val set results: val_loss: 1.3228 val_acc: 0.6920 val_f1: 0.6920
INFO:root:Test set results: test_loss: 1.3237 test_acc: 0.6760 test_f1: 0.6760
INFO:root:Saved model in /content/logs/nc/2024_7_1/151

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0000 train_acc: 1.0000 train_f1: 1.0000 time: 0.0087s
INFO:root:Epoch: 0050 val_loss: 3.1928 val_acc: 0.6200 val_f1: 0.6200
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.6284s
INFO:root:Val set results: val_loss: 1.3310 val_acc: 0.6880 val_f1: 0.6880
INFO:root:Test set results: test_loss: 1.3321 test_acc: 0.6750 test_f1: 0.6750
INFO:root:Saved model in /content/logs/nc/2024_7_1/152

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0.2, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0020 train_acc: 1.0000 train_f1: 1.0000 time: 0.0089s
INFO:root:Epoch: 0050 val_loss: 2.6419 val_acc: 0.6460 val_f1: 0.6460
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.6858s
INFO:root:Val set results: val_loss: 1.1227 val_acc: 0.6980 val_f1: 0.6980
INFO:root:Test set results: test_loss: 1.1304 test_acc: 0.6770 test_f1: 0.6770
INFO:root:Saved model in /content/logs/nc/2024_7_1/153

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0.2, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0048 train_acc: 1.0000 train_f1: 1.0000 time: 0.0089s
INFO:root:Epoch: 0050 val_loss: 2.3184 val_acc: 0.6520 val_f1: 0.6520
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.6425s
INFO:root:Val set results: val_loss: 1.3392 val_acc: 0.6900 val_f1: 0.6900
INFO:root:Test set results: test_loss: 1.3445 test_acc: 0.6680 test_f1: 0.6680
INFO:root:Saved model in /content/logs/nc/2024_7_1/154

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0.2, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0013 train_acc: 1.0000 train_f1: 1.0000 time: 0.0089s
INFO:root:Epoch: 0050 val_loss: 2.7021 val_acc: 0.6440 val_f1: 0.6440
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.6462s
INFO:root:Val set results: val_loss: 1.3460 val_acc: 0.6960 val_f1: 0.6960
INFO:root:Test set results: test_loss: 1.3513 test_acc: 0.6670 test_f1: 0.6670
INFO:root:Saved model in /content/logs/nc/2024_7_1/155

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0.5, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0838 train_acc: 0.9667 train_f1: 0.9667 time: 0.0092s
INFO:root:Epoch: 0050 val_loss: 2.2622 val_acc: 0.6280 val_f1: 0.6280
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 3.0176s
INFO:root:Val set results: val_loss: 1.3706 val_acc: 0.7060 val_f1: 0.7060
INFO:root:Test set results: test_loss: 1.3722 test_acc: 0.6730 test_f1: 0.6730
INFO:root:Saved model in /content/logs/nc/2024_7_1/156

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0.5, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0875 train_acc: 0.9583 train_f1: 0.9583 time: 0.0116s
INFO:root:Epoch: 0050 val_loss: 1.9647 val_acc: 0.6340 val_f1: 0.6340
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.8958s
INFO:root:Val set results: val_loss: 1.0855 val_acc: 0.7000 val_f1: 0.7000
INFO:root:Test set results: test_loss: 1.0910 test_acc: 0.6820 test_f1: 0.6820
INFO:root:Saved model in /content/logs/nc/2024_7_1/157

================================================================================
Experiment with num_layers=2, weight_decay=0, dropout=0.5, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0957 train_acc: 0.9500 train_f1: 0.9500 time: 0.0089s
INFO:root:Epoch: 0050 val_loss: 2.2806 val_acc: 0.6280 val_f1: 0.6280
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.6410s
INFO:root:Val set results: val_loss: 1.0890 val_acc: 0.7040 val_f1: 0.7040
INFO:root:Test set results: test_loss: 1.0942 test_acc: 0.6810 test_f1: 0.6810
INFO:root:Saved model in /content/logs/nc/2024_7_1/158

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0152 train_acc: 1.0000 train_f1: 1.0000 time: 0.0089s
INFO:root:Epoch: 0050 val_loss: 1.0180 val_acc: 0.6720 val_f1: 0.6720
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.9812s
INFO:root:Val set results: val_loss: 0.9988 val_acc: 0.6900 val_f1: 0.6900
INFO:root:Test set results: test_loss: 1.0115 test_acc: 0.6770 test_f1: 0.6770
INFO:root:Saved model in /content/logs/nc/2024_7_1/159

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0152 train_acc: 1.0000 train_f1: 1.0000 time: 0.0129s
INFO:root:Epoch: 0050 val_loss: 1.0065 val_acc: 0.6800 val_f1: 0.6800
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7833s
INFO:root:Val set results: val_loss: 1.3252 val_acc: 0.6960 val_f1: 0.6960
INFO:root:Test set results: test_loss: 1.3269 test_acc: 0.6820 test_f1: 0.6820
INFO:root:Saved model in /content/logs/nc/2024_7_1/160

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0151 train_acc: 1.0000 train_f1: 1.0000 time: 0.0089s
INFO:root:Epoch: 0050 val_loss: 1.0089 val_acc: 0.6740 val_f1: 0.6740
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.6616s
INFO:root:Val set results: val_loss: 1.1436 val_acc: 0.6960 val_f1: 0.6960
INFO:root:Test set results: test_loss: 1.1489 test_acc: 0.6830 test_f1: 0.6830
INFO:root:Saved model in /content/logs/nc/2024_7_1/161

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0.2, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0279 train_acc: 1.0000 train_f1: 1.0000 time: 0.0091s
INFO:root:Epoch: 0050 val_loss: 1.1075 val_acc: 0.6700 val_f1: 0.6700
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.5775s
INFO:root:Val set results: val_loss: 1.2827 val_acc: 0.7000 val_f1: 0.7000
INFO:root:Test set results: test_loss: 1.2906 test_acc: 0.6860 test_f1: 0.6860
INFO:root:Saved model in /content/logs/nc/2024_7_1/162

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0.2, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0283 train_acc: 1.0000 train_f1: 1.0000 time: 0.0118s
INFO:root:Epoch: 0050 val_loss: 1.0823 val_acc: 0.6840 val_f1: 0.6840
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.9488s
INFO:root:Val set results: val_loss: 1.1756 val_acc: 0.6980 val_f1: 0.6980
INFO:root:Test set results: test_loss: 1.1744 test_acc: 0.6820 test_f1: 0.6820
INFO:root:Saved model in /content/logs/nc/2024_7_1/163

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0.2, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0241 train_acc: 1.0000 train_f1: 1.0000 time: 0.0089s
INFO:root:Epoch: 0050 val_loss: 1.0916 val_acc: 0.6740 val_f1: 0.6740
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7169s
INFO:root:Val set results: val_loss: 1.0749 val_acc: 0.7000 val_f1: 0.7000
INFO:root:Test set results: test_loss: 1.0499 test_acc: 0.6900 test_f1: 0.6900
INFO:root:Saved model in /content/logs/nc/2024_7_1/164

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0.5, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.1306 train_acc: 0.9667 train_f1: 0.9667 time: 0.0125s
INFO:root:Epoch: 0050 val_loss: 1.2803 val_acc: 0.6460 val_f1: 0.6460
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.3995s
INFO:root:Val set results: val_loss: 1.3704 val_acc: 0.7140 val_f1: 0.7140
INFO:root:Test set results: test_loss: 1.3710 test_acc: 0.6820 test_f1: 0.6820
INFO:root:Saved model in /content/logs/nc/2024_7_1/165

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0.5, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.1180 train_acc: 0.9667 train_f1: 0.9667 time: 0.0089s
INFO:root:Epoch: 0050 val_loss: 1.2406 val_acc: 0.6680 val_f1: 0.6680
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.6551s
INFO:root:Val set results: val_loss: 1.2270 val_acc: 0.7060 val_f1: 0.7060
INFO:root:Test set results: test_loss: 1.2330 test_acc: 0.6880 test_f1: 0.6880
INFO:root:Saved model in /content/logs/nc/2024_7_1/166

================================================================================
Experiment with num_layers=2, weight_decay=0.001, dropout=0.5, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 474886
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.1237 train_acc: 0.9667 train_f1: 0.9667 time: 0.0090s
INFO:root:Epoch: 0050 val_loss: 1.2429 val_acc: 0.6540 val_f1: 0.6540
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.6774s
INFO:root:Val set results: val_loss: 1.0902 val_acc: 0.7060 val_f1: 0.7060
INFO:root:Test set results: test_loss: 1.0957 test_acc: 0.6910 test_f1: 0.6910
INFO:root:Saved model in /content/logs/nc/2024_7_1/167

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0000 train_acc: 1.0000 train_f1: 1.0000 time: 0.0103s
INFO:root:Epoch: 0050 val_loss: 8.7248 val_acc: 0.6220 val_f1: 0.6220
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7725s
INFO:root:Val set results: val_loss: 1.0582 val_acc: 0.6500 val_f1: 0.6500
INFO:root:Test set results: test_loss: 1.0899 test_acc: 0.6370 test_f1: 0.6370
INFO:root:Saved model in /content/logs/nc/2024_7_1/168

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0001 train_acc: 1.0000 train_f1: 1.0000 time: 0.0105s
INFO:root:Epoch: 0050 val_loss: 4.0083 val_acc: 0.6120 val_f1: 0.6120
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7642s
INFO:root:Val set results: val_loss: 1.6350 val_acc: 0.6860 val_f1: 0.6860
INFO:root:Test set results: test_loss: 1.6346 test_acc: 0.6740 test_f1: 0.6740
INFO:root:Saved model in /content/logs/nc/2024_7_1/169

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0000 train_acc: 1.0000 train_f1: 1.0000 time: 0.0136s
INFO:root:Epoch: 0050 val_loss: 10.1887 val_acc: 0.5940 val_f1: 0.5940
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.1318s
INFO:root:Val set results: val_loss: 1.6425 val_acc: 0.6820 val_f1: 0.6820
INFO:root:Test set results: test_loss: 1.6421 test_acc: 0.6730 test_f1: 0.6730
INFO:root:Saved model in /content/logs/nc/2024_7_1/170

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0.2, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0203 train_acc: 0.9750 train_f1: 0.9750 time: 0.0108s
INFO:root:Epoch: 0050 val_loss: 6.7178 val_acc: 0.5940 val_f1: 0.5940
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7954s
INFO:root:Val set results: val_loss: 1.1219 val_acc: 0.6700 val_f1: 0.6700
INFO:root:Test set results: test_loss: 1.1266 test_acc: 0.6570 test_f1: 0.6570
INFO:root:Saved model in /content/logs/nc/2024_7_1/171

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0.2, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0183 train_acc: 0.9833 train_f1: 0.9833 time: 0.0107s
INFO:root:Epoch: 0050 val_loss: 3.7925 val_acc: 0.6360 val_f1: 0.6360
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.9508s
INFO:root:Val set results: val_loss: 1.3424 val_acc: 0.6920 val_f1: 0.6920
INFO:root:Test set results: test_loss: 1.3476 test_acc: 0.6840 test_f1: 0.6840
INFO:root:Saved model in /content/logs/nc/2024_7_1/172

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0.2, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0119 train_acc: 0.9833 train_f1: 0.9833 time: 0.0107s
INFO:root:Epoch: 0050 val_loss: 6.9172 val_acc: 0.6100 val_f1: 0.6100
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7832s
INFO:root:Val set results: val_loss: 1.3680 val_acc: 0.6980 val_f1: 0.6980
INFO:root:Test set results: test_loss: 1.3699 test_acc: 0.6810 test_f1: 0.6810
INFO:root:Saved model in /content/logs/nc/2024_7_1/173

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0.5, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.1440 train_acc: 0.9250 train_f1: 0.9250 time: 0.0107s
INFO:root:Epoch: 0050 val_loss: 2.9857 val_acc: 0.6520 val_f1: 0.6520
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.8204s
INFO:root:Val set results: val_loss: 1.0693 val_acc: 0.6740 val_f1: 0.6740
INFO:root:Test set results: test_loss: 1.0737 test_acc: 0.6560 test_f1: 0.6560
INFO:root:Saved model in /content/logs/nc/2024_7_1/174

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0.5, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.1386 train_acc: 0.9167 train_f1: 0.9167 time: 0.0149s
INFO:root:Epoch: 0050 val_loss: 2.9076 val_acc: 0.6200 val_f1: 0.6200
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.1585s
INFO:root:Val set results: val_loss: 1.6889 val_acc: 0.6880 val_f1: 0.6880
INFO:root:Test set results: test_loss: 1.6864 test_acc: 0.6770 test_f1: 0.6770
INFO:root:Saved model in /content/logs/nc/2024_7_1/175

================================================================================
Experiment with num_layers=3, weight_decay=0, dropout=0.5, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.1623 train_acc: 0.9167 train_f1: 0.9167 time: 0.0111s
INFO:root:Epoch: 0050 val_loss: 3.6468 val_acc: 0.6480 val_f1: 0.6480
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7573s
INFO:root:Val set results: val_loss: 1.6929 val_acc: 0.6740 val_f1: 0.6740
INFO:root:Test set results: test_loss: 1.6904 test_acc: 0.6740 test_f1: 0.6740
INFO:root:Saved model in /content/logs/nc/2024_7_1/176

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0074 train_acc: 1.0000 train_f1: 1.0000 time: 0.0107s
INFO:root:Epoch: 0050 val_loss: 1.3406 val_acc: 0.6720 val_f1: 0.6720
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.0128s
INFO:root:Val set results: val_loss: 1.9673 val_acc: 0.6840 val_f1: 0.6840
INFO:root:Test set results: test_loss: 1.8890 test_acc: 0.6640 test_f1: 0.6640
INFO:root:Saved model in /content/logs/nc/2024_7_1/177

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0051 train_acc: 1.0000 train_f1: 1.0000 time: 0.0109s
INFO:root:Epoch: 0050 val_loss: 1.8606 val_acc: 0.6420 val_f1: 0.6420
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7352s
INFO:root:Val set results: val_loss: 1.6448 val_acc: 0.7020 val_f1: 0.7020
INFO:root:Test set results: test_loss: 1.6452 test_acc: 0.6830 test_f1: 0.6830
INFO:root:Saved model in /content/logs/nc/2024_7_1/178

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0038 train_acc: 1.0000 train_f1: 1.0000 time: 0.0103s
INFO:root:Epoch: 0050 val_loss: 1.9699 val_acc: 0.6520 val_f1: 0.6520
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7816s
INFO:root:Val set results: val_loss: 1.6525 val_acc: 0.7000 val_f1: 0.7000
INFO:root:Test set results: test_loss: 1.6525 test_acc: 0.6810 test_f1: 0.6810
INFO:root:Saved model in /content/logs/nc/2024_7_1/179

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0.2, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0228 train_acc: 0.9833 train_f1: 0.9833 time: 0.0152s
INFO:root:Epoch: 0050 val_loss: 1.5867 val_acc: 0.6600 val_f1: 0.6600
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.2705s
INFO:root:Val set results: val_loss: 1.8700 val_acc: 0.6860 val_f1: 0.6860
INFO:root:Test set results: test_loss: 1.9136 test_acc: 0.6730 test_f1: 0.6730
INFO:root:Saved model in /content/logs/nc/2024_7_1/180

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0.2, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0282 train_acc: 0.9833 train_f1: 0.9833 time: 0.0104s
INFO:root:Epoch: 0050 val_loss: 2.1090 val_acc: 0.6000 val_f1: 0.6000
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7823s
INFO:root:Val set results: val_loss: 1.3612 val_acc: 0.7020 val_f1: 0.7020
INFO:root:Test set results: test_loss: 1.3657 test_acc: 0.6830 test_f1: 0.6830
INFO:root:Saved model in /content/logs/nc/2024_7_1/181

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0.2, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.0344 train_acc: 0.9750 train_f1: 0.9750 time: 0.0106s
INFO:root:Epoch: 0050 val_loss: 1.7011 val_acc: 0.6580 val_f1: 0.6580
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.9848s
INFO:root:Val set results: val_loss: 1.3870 val_acc: 0.7060 val_f1: 0.7060
INFO:root:Test set results: test_loss: 1.3883 test_acc: 0.6870 test_f1: 0.6870
INFO:root:Saved model in /content/logs/nc/2024_7_1/182

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0.5, activation=relu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.1402 train_acc: 0.9250 train_f1: 0.9250 time: 0.0108s
INFO:root:Epoch: 0050 val_loss: 1.6697 val_acc: 0.6700 val_f1: 0.6700
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.9012s
INFO:root:Val set results: val_loss: 1.6831 val_acc: 0.6820 val_f1: 0.6820
INFO:root:Test set results: test_loss: 1.6726 test_acc: 0.6650 test_f1: 0.6650
INFO:root:Saved model in /content/logs/nc/2024_7_1/183

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0.5, activation=tanh
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.1487 train_acc: 0.9167 train_f1: 0.9167 time: 0.0107s
INFO:root:Epoch: 0050 val_loss: 1.9378 val_acc: 0.6520 val_f1: 0.6520
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 1.7639s
INFO:root:Val set results: val_loss: 1.1692 val_acc: 0.6940 val_f1: 0.6940
INFO:root:Test set results: test_loss: 1.1741 test_acc: 0.6860 test_f1: 0.6860
INFO:root:Saved model in /content/logs/nc/2024_7_1/184

================================================================================
Experiment with num_layers=3, weight_decay=0.001, dropout=0.5, activation=elu
INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
/content/GCN-Pseudo-Riemannian-Manifold/utils/data_utils.py:111: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO:root:Number of nodes: 3327
INFO:root:Number of features: 3703
INFO:root:Number of classes: 6
INFO:root:NCModel(
  (encoder): GCN(
    (layers): Sequential(
      (0): GraphConvolution(
        input_dim=3703, output_dim=128
        (linear): Linear(in_features=3703, out_features=128, bias=True)
      )
      (1): GraphConvolution(
        input_dim=128, output_dim=128
        (linear): Linear(in_features=128, out_features=128, bias=True)
      )
    )
  )
  (decoder): GCNDecoder(
    (cls): GraphConvolution(
      input_dim=128, output_dim=6
      (linear): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 491398
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:402: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
INFO:root:Epoch: 0050 lr: 0.0025 train_loss: 0.1482 train_acc: 0.9333 train_f1: 0.9333 time: 0.0158s
INFO:root:Epoch: 0050 val_loss: 1.7863 val_acc: 0.6560 val_f1: 0.6560
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 2.4270s
INFO:root:Val set results: val_loss: 1.7343 val_acc: 0.6840 val_f1: 0.6840
INFO:root:Test set results: test_loss: 1.8891 test_acc: 0.6580 test_f1: 0.6580
INFO:root:Saved model in /content/logs/nc/2024_7_1/185

================================================================================
