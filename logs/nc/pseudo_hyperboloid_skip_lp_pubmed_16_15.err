INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
INFO:root:LPModel(
  (encoder): HGCN(
    (layers): Sequential(
      (0): HyperbolicGraphConvolution(
        (linear): HypLinear(
          in_features=501, out_features=16, c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (agg): HypAgg(
          c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (hyp_act): HypAct(
          c_in=Parameter containing:
          tensor([-1.], requires_grad=True), c_out=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
      )
      (1): HyperbolicGraphConvolution(
        (linear): HypLinear(
          in_features=16, out_features=16, c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (agg): HypAgg(
          c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (hyp_act): HypAct(
          c_in=Parameter containing:
          tensor([-1.], requires_grad=True), c_out=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
      )
    )
  )
  (dc): FermiDiracDecoder()
)
INFO:root:Total number of parameters: 8307
/workspace/anaconda3/envs/geo/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  "please use `get_last_lr()`.", UserWarning)
INFO:root:Epoch: 0005 lr: 0.01 train_loss: 1.8303 train_roc: 0.7941 train_ap: 0.7856 time: 2.2403s
INFO:root:Epoch: 0005 val_loss: 1.7666 val_roc: 0.7917 val_ap: 0.7895
INFO:root:Epoch: 0010 lr: 0.01 train_loss: 1.7470 train_roc: 0.8336 train_ap: 0.8232 time: 2.1905s
INFO:root:Epoch: 0010 val_loss: 1.5889 val_roc: 0.8410 val_ap: 0.8369
INFO:root:Epoch: 0015 lr: 0.01 train_loss: 1.5463 train_roc: 0.8880 train_ap: 0.8787 time: 0.9333s
INFO:root:Epoch: 0015 val_loss: 1.3617 val_roc: 0.8632 val_ap: 0.8557
INFO:root:Epoch: 0020 lr: 0.01 train_loss: 1.3700 train_roc: 0.8994 train_ap: 0.8877 time: 0.8956s
INFO:root:Epoch: 0020 val_loss: 1.1444 val_roc: 0.8701 val_ap: 0.8628
INFO:root:Epoch: 0025 lr: 0.01 train_loss: 1.0065 train_roc: 0.9240 train_ap: 0.9118 time: 1.9589s
INFO:root:Epoch: 0025 val_loss: 0.9502 val_roc: 0.8788 val_ap: 0.8710
INFO:root:Epoch: 0030 lr: 0.01 train_loss: 0.7913 train_roc: 0.9309 train_ap: 0.9176 time: 2.1976s
INFO:root:Epoch: 0030 val_loss: 0.8724 val_roc: 0.8859 val_ap: 0.8787
INFO:root:Epoch: 0035 lr: 0.01 train_loss: 0.6237 train_roc: 0.9455 train_ap: 0.9351 time: 2.2775s
INFO:root:Epoch: 0035 val_loss: 0.9915 val_roc: 0.8952 val_ap: 0.8886
INFO:root:Epoch: 0040 lr: 0.01 train_loss: 0.6092 train_roc: 0.9579 train_ap: 0.9489 time: 2.2360s
INFO:root:Epoch: 0040 val_loss: 1.1893 val_roc: 0.9041 val_ap: 0.8966
INFO:root:Epoch: 0045 lr: 0.01 train_loss: 0.5807 train_roc: 0.9592 train_ap: 0.9520 time: 2.1759s
INFO:root:Epoch: 0045 val_loss: 1.0184 val_roc: 0.9124 val_ap: 0.9058
INFO:root:Epoch: 0050 lr: 0.01 train_loss: 0.5486 train_roc: 0.9640 train_ap: 0.9571 time: 2.1090s
INFO:root:Epoch: 0050 val_loss: 0.8479 val_roc: 0.9219 val_ap: 0.9169
INFO:root:Epoch: 0055 lr: 0.01 train_loss: 0.5120 train_roc: 0.9670 train_ap: 0.9587 time: 2.3122s
INFO:root:Epoch: 0055 val_loss: 0.8568 val_roc: 0.9326 val_ap: 0.9273
INFO:root:Epoch: 0060 lr: 0.01 train_loss: 0.4753 train_roc: 0.9771 train_ap: 0.9726 time: 2.1972s
INFO:root:Epoch: 0060 val_loss: 0.8430 val_roc: 0.9359 val_ap: 0.9315
INFO:root:Epoch: 0065 lr: 0.01 train_loss: 0.4827 train_roc: 0.9762 train_ap: 0.9707 time: 2.1759s
INFO:root:Epoch: 0065 val_loss: 0.8361 val_roc: 0.9378 val_ap: 0.9341
INFO:root:Epoch: 0070 lr: 0.01 train_loss: 0.4810 train_roc: 0.9758 train_ap: 0.9714 time: 2.1989s
INFO:root:Epoch: 0070 val_loss: 0.8198 val_roc: 0.9386 val_ap: 0.9356
INFO:root:Epoch: 0075 lr: 0.01 train_loss: 0.4498 train_roc: 0.9797 train_ap: 0.9756 time: 2.3152s
INFO:root:Epoch: 0075 val_loss: 0.7697 val_roc: 0.9421 val_ap: 0.9395
INFO:root:Epoch: 0080 lr: 0.01 train_loss: 0.4378 train_roc: 0.9837 train_ap: 0.9817 time: 2.1710s
INFO:root:Epoch: 0080 val_loss: 0.8436 val_roc: 0.9448 val_ap: 0.9426
INFO:root:Epoch: 0085 lr: 0.01 train_loss: 0.4382 train_roc: 0.9830 train_ap: 0.9783 time: 2.2773s
INFO:root:Epoch: 0085 val_loss: 0.7976 val_roc: 0.9454 val_ap: 0.9437
INFO:root:Epoch: 0090 lr: 0.01 train_loss: 0.4264 train_roc: 0.9851 train_ap: 0.9822 time: 2.1810s
INFO:root:Epoch: 0090 val_loss: 0.7442 val_roc: 0.9466 val_ap: 0.9451
INFO:root:Epoch: 0095 lr: 0.01 train_loss: 0.4150 train_roc: 0.9849 train_ap: 0.9816 time: 2.2558s
INFO:root:Epoch: 0095 val_loss: 0.7824 val_roc: 0.9476 val_ap: 0.9460
INFO:root:Epoch: 0100 lr: 0.01 train_loss: 0.4167 train_roc: 0.9858 train_ap: 0.9833 time: 2.2232s
INFO:root:Epoch: 0100 val_loss: 0.8327 val_roc: 0.9490 val_ap: 0.9472
INFO:root:Epoch: 0105 lr: 0.01 train_loss: 0.4431 train_roc: 0.9840 train_ap: 0.9810 time: 2.2203s
INFO:root:Epoch: 0105 val_loss: 0.7511 val_roc: 0.9504 val_ap: 0.9485
INFO:root:Epoch: 0110 lr: 0.01 train_loss: 0.4198 train_roc: 0.9855 train_ap: 0.9829 time: 2.2652s
INFO:root:Epoch: 0110 val_loss: 0.7399 val_roc: 0.9508 val_ap: 0.9486
INFO:root:Epoch: 0115 lr: 0.01 train_loss: 0.4178 train_roc: 0.9864 train_ap: 0.9837 time: 2.3261s
INFO:root:Epoch: 0115 val_loss: 0.7411 val_roc: 0.9518 val_ap: 0.9498
INFO:root:Epoch: 0120 lr: 0.01 train_loss: 0.3988 train_roc: 0.9870 train_ap: 0.9830 time: 2.1814s
INFO:root:Epoch: 0120 val_loss: 0.7701 val_roc: 0.9525 val_ap: 0.9504
INFO:root:Epoch: 0125 lr: 0.01 train_loss: 0.4312 train_roc: 0.9873 train_ap: 0.9858 time: 2.1857s
INFO:root:Epoch: 0125 val_loss: 0.7393 val_roc: 0.9522 val_ap: 0.9504
INFO:root:Epoch: 0130 lr: 0.01 train_loss: 0.3936 train_roc: 0.9887 train_ap: 0.9865 time: 2.2667s
INFO:root:Epoch: 0130 val_loss: 0.8425 val_roc: 0.9528 val_ap: 0.9511
INFO:root:Epoch: 0135 lr: 0.01 train_loss: 0.4050 train_roc: 0.9861 train_ap: 0.9817 time: 2.1706s
INFO:root:Epoch: 0135 val_loss: 0.7262 val_roc: 0.9519 val_ap: 0.9504
INFO:root:Epoch: 0140 lr: 0.01 train_loss: 0.4127 train_roc: 0.9869 train_ap: 0.9841 time: 2.2197s
INFO:root:Epoch: 0140 val_loss: 0.7487 val_roc: 0.9530 val_ap: 0.9517
INFO:root:Epoch: 0145 lr: 0.01 train_loss: 0.4207 train_roc: 0.9852 train_ap: 0.9829 time: 2.1818s
INFO:root:Epoch: 0145 val_loss: 0.8957 val_roc: 0.9551 val_ap: 0.9536
INFO:root:Epoch: 0150 lr: 0.01 train_loss: 0.3909 train_roc: 0.9891 train_ap: 0.9865 time: 2.0638s
INFO:root:Epoch: 0150 val_loss: 0.6833 val_roc: 0.9532 val_ap: 0.9519
INFO:root:Epoch: 0155 lr: 0.01 train_loss: 0.4176 train_roc: 0.9880 train_ap: 0.9856 time: 2.1712s
INFO:root:Epoch: 0155 val_loss: 0.7034 val_roc: 0.9534 val_ap: 0.9519
INFO:root:Epoch: 0160 lr: 0.01 train_loss: 0.4062 train_roc: 0.9881 train_ap: 0.9855 time: 2.1897s
INFO:root:Epoch: 0160 val_loss: 0.8031 val_roc: 0.9544 val_ap: 0.9529
INFO:root:Epoch: 0165 lr: 0.01 train_loss: 0.4080 train_roc: 0.9857 train_ap: 0.9824 time: 2.2049s
INFO:root:Epoch: 0165 val_loss: 0.6960 val_roc: 0.9538 val_ap: 0.9526
INFO:root:Epoch: 0170 lr: 0.01 train_loss: 0.3957 train_roc: 0.9894 train_ap: 0.9877 time: 2.2185s
INFO:root:Epoch: 0170 val_loss: 0.7499 val_roc: 0.9552 val_ap: 0.9540
INFO:root:Epoch: 0175 lr: 0.01 train_loss: 0.3986 train_roc: 0.9877 train_ap: 0.9841 time: 2.1998s
INFO:root:Epoch: 0175 val_loss: 0.8979 val_roc: 0.9556 val_ap: 0.9543
INFO:root:Epoch: 0180 lr: 0.01 train_loss: 0.4093 train_roc: 0.9884 train_ap: 0.9855 time: 2.2059s
INFO:root:Epoch: 0180 val_loss: 0.7118 val_roc: 0.9549 val_ap: 0.9536
INFO:root:Epoch: 0185 lr: 0.01 train_loss: 0.3862 train_roc: 0.9897 train_ap: 0.9877 time: 2.1862s
INFO:root:Epoch: 0185 val_loss: 0.6884 val_roc: 0.9549 val_ap: 0.9536
INFO:root:Epoch: 0190 lr: 0.01 train_loss: 0.4034 train_roc: 0.9900 train_ap: 0.9870 time: 2.2280s
INFO:root:Epoch: 0190 val_loss: 0.8033 val_roc: 0.9549 val_ap: 0.9535
INFO:root:Epoch: 0195 lr: 0.01 train_loss: 0.4055 train_roc: 0.9875 train_ap: 0.9852 time: 2.2273s
INFO:root:Epoch: 0195 val_loss: 0.8401 val_roc: 0.9537 val_ap: 0.9524
INFO:root:Epoch: 0200 lr: 0.01 train_loss: 0.3895 train_roc: 0.9894 train_ap: 0.9867 time: 2.2303s
INFO:root:Epoch: 0200 val_loss: 0.7201 val_roc: 0.9527 val_ap: 0.9511
INFO:root:Epoch: 0205 lr: 0.01 train_loss: 0.3937 train_roc: 0.9877 train_ap: 0.9845 time: 2.2731s
INFO:root:Epoch: 0205 val_loss: 0.6653 val_roc: 0.9518 val_ap: 0.9499
INFO:root:Epoch: 0210 lr: 0.01 train_loss: 0.3966 train_roc: 0.9877 train_ap: 0.9858 time: 2.1734s
INFO:root:Epoch: 0210 val_loss: 0.7324 val_roc: 0.9530 val_ap: 0.9507
INFO:root:Epoch: 0215 lr: 0.01 train_loss: 0.3957 train_roc: 0.9879 train_ap: 0.9845 time: 2.2186s
INFO:root:Epoch: 0215 val_loss: 0.7458 val_roc: 0.9545 val_ap: 0.9519
INFO:root:Epoch: 0220 lr: 0.01 train_loss: 0.3897 train_roc: 0.9893 train_ap: 0.9867 time: 2.2155s
INFO:root:Epoch: 0220 val_loss: 0.7228 val_roc: 0.9551 val_ap: 0.9527
INFO:root:Epoch: 0225 lr: 0.01 train_loss: 0.3796 train_roc: 0.9899 train_ap: 0.9881 time: 2.2018s
INFO:root:Epoch: 0225 val_loss: 0.7374 val_roc: 0.9556 val_ap: 0.9532
INFO:root:Epoch: 0230 lr: 0.01 train_loss: 0.3844 train_roc: 0.9896 train_ap: 0.9871 time: 2.2209s
INFO:root:Epoch: 0230 val_loss: 0.8141 val_roc: 0.9559 val_ap: 0.9535
INFO:root:Epoch: 0235 lr: 0.01 train_loss: 0.4147 train_roc: 0.9885 train_ap: 0.9863 time: 2.1942s
INFO:root:Epoch: 0235 val_loss: 0.6642 val_roc: 0.9548 val_ap: 0.9524
INFO:root:Epoch: 0240 lr: 0.01 train_loss: 0.3798 train_roc: 0.9904 train_ap: 0.9884 time: 2.2590s
INFO:root:Epoch: 0240 val_loss: 0.7138 val_roc: 0.9543 val_ap: 0.9522
INFO:root:Epoch: 0245 lr: 0.01 train_loss: 0.3981 train_roc: 0.9880 train_ap: 0.9849 time: 2.2385s
INFO:root:Epoch: 0245 val_loss: 0.8104 val_roc: 0.9542 val_ap: 0.9525
INFO:root:Epoch: 0250 lr: 0.01 train_loss: 0.3824 train_roc: 0.9906 train_ap: 0.9891 time: 2.1924s
INFO:root:Epoch: 0250 val_loss: 0.7248 val_roc: 0.9538 val_ap: 0.9521
INFO:root:Epoch: 0255 lr: 0.01 train_loss: 0.4117 train_roc: 0.9868 train_ap: 0.9842 time: 2.2391s
INFO:root:Epoch: 0255 val_loss: 0.7803 val_roc: 0.9528 val_ap: 0.9509
INFO:root:Epoch: 0260 lr: 0.01 train_loss: 0.4053 train_roc: 0.9873 train_ap: 0.9849 time: 2.2497s
INFO:root:Epoch: 0260 val_loss: 0.7840 val_roc: 0.9514 val_ap: 0.9499
INFO:root:Epoch: 0265 lr: 0.01 train_loss: 0.3840 train_roc: 0.9885 train_ap: 0.9863 time: 2.0414s
INFO:root:Epoch: 0265 val_loss: 0.6990 val_roc: 0.9513 val_ap: 0.9499
INFO:root:Epoch: 0270 lr: 0.01 train_loss: 0.4191 train_roc: 0.9891 train_ap: 0.9866 time: 2.2057s
INFO:root:Epoch: 0270 val_loss: 0.6350 val_roc: 0.9510 val_ap: 0.9498
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 766.9783s
INFO:root:Val set results: val_loss: 0.8611 val_roc: 0.9556 val_ap: 0.9544
INFO:root:Test set results: test_loss: 0.8916 test_roc: 0.9542 test_ap: 0.9521
INFO:root:Saved model in /workspace/xiongbo/hgcn/logs/lp/2021_5_2/22
