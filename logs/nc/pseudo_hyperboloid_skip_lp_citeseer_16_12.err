INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
INFO:root:LPModel(
  (encoder): HGCN(
    (layers): Sequential(
      (0): HyperbolicGraphConvolution(
        (linear): HypLinear(
          in_features=3704, out_features=16, c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (agg): HypAgg(
          c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (hyp_act): HypAct(
          c_in=Parameter containing:
          tensor([-1.], requires_grad=True), c_out=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
      )
      (1): HyperbolicGraphConvolution(
        (linear): HypLinear(
          in_features=16, out_features=16, c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (agg): HypAgg(
          c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (hyp_act): HypAct(
          c_in=Parameter containing:
          tensor([-1.], requires_grad=True), c_out=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
      )
    )
  )
  (dc): FermiDiracDecoder()
)
INFO:root:Total number of parameters: 59555
/workspace/anaconda3/envs/geo/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  "please use `get_last_lr()`.", UserWarning)
INFO:root:Epoch: 0005 lr: 0.01 train_loss: 1.8900 train_roc: 0.7778 train_ap: 0.7632 time: 1.0033s
INFO:root:Epoch: 0005 val_loss: 1.8022 val_roc: 0.8136 val_ap: 0.8245
INFO:root:Epoch: 0010 lr: 0.01 train_loss: 1.7480 train_roc: 0.8849 train_ap: 0.8735 time: 0.9690s
INFO:root:Epoch: 0010 val_loss: 1.6356 val_roc: 0.8496 val_ap: 0.8677
INFO:root:Epoch: 0015 lr: 0.01 train_loss: 1.5781 train_roc: 0.9221 train_ap: 0.9113 time: 0.9260s
INFO:root:Epoch: 0015 val_loss: 1.4078 val_roc: 0.8657 val_ap: 0.8795
INFO:root:Epoch: 0020 lr: 0.01 train_loss: 1.3958 train_roc: 0.9449 train_ap: 0.9379 time: 0.9459s
INFO:root:Epoch: 0020 val_loss: 1.1796 val_roc: 0.8782 val_ap: 0.8871
INFO:root:Epoch: 0025 lr: 0.01 train_loss: 1.0614 train_roc: 0.9610 train_ap: 0.9525 time: 0.9564s
INFO:root:Epoch: 0025 val_loss: 0.9487 val_roc: 0.8882 val_ap: 0.9003
INFO:root:Epoch: 0030 lr: 0.01 train_loss: 0.8619 train_roc: 0.9649 train_ap: 0.9557 time: 0.9628s
INFO:root:Epoch: 0030 val_loss: 0.9039 val_roc: 0.8818 val_ap: 0.8939
INFO:root:Epoch: 0035 lr: 0.01 train_loss: 0.5552 train_roc: 0.9707 train_ap: 0.9640 time: 0.9596s
INFO:root:Epoch: 0035 val_loss: 1.0930 val_roc: 0.8911 val_ap: 0.9031
INFO:root:Epoch: 0040 lr: 0.01 train_loss: 0.4283 train_roc: 0.9809 train_ap: 0.9728 time: 0.9572s
INFO:root:Epoch: 0040 val_loss: 1.6153 val_roc: 0.8953 val_ap: 0.9057
INFO:root:Epoch: 0045 lr: 0.01 train_loss: 0.3982 train_roc: 0.9845 train_ap: 0.9768 time: 0.9829s
INFO:root:Epoch: 0045 val_loss: 2.1083 val_roc: 0.9009 val_ap: 0.9102
INFO:root:Epoch: 0050 lr: 0.01 train_loss: 0.3596 train_roc: 0.9881 train_ap: 0.9834 time: 1.0030s
INFO:root:Epoch: 0050 val_loss: 2.0647 val_roc: 0.9032 val_ap: 0.9096
INFO:root:Epoch: 0055 lr: 0.01 train_loss: 0.3442 train_roc: 0.9903 train_ap: 0.9873 time: 1.0043s
INFO:root:Epoch: 0055 val_loss: 1.8046 val_roc: 0.9087 val_ap: 0.9046
INFO:root:Epoch: 0060 lr: 0.01 train_loss: 0.3068 train_roc: 0.9918 train_ap: 0.9868 time: 1.0458s
INFO:root:Epoch: 0060 val_loss: 1.6548 val_roc: 0.9187 val_ap: 0.9220
INFO:root:Epoch: 0065 lr: 0.01 train_loss: 0.3071 train_roc: 0.9909 train_ap: 0.9833 time: 0.9833s
INFO:root:Epoch: 0065 val_loss: 1.5931 val_roc: 0.9251 val_ap: 0.9282
INFO:root:Epoch: 0070 lr: 0.01 train_loss: 0.2791 train_roc: 0.9943 train_ap: 0.9904 time: 0.9867s
INFO:root:Epoch: 0070 val_loss: 1.6597 val_roc: 0.9276 val_ap: 0.9304
INFO:root:Epoch: 0075 lr: 0.01 train_loss: 0.2882 train_roc: 0.9939 train_ap: 0.9920 time: 0.9808s
INFO:root:Epoch: 0075 val_loss: 1.8107 val_roc: 0.9253 val_ap: 0.9232
INFO:root:Epoch: 0080 lr: 0.01 train_loss: 0.2766 train_roc: 0.9943 train_ap: 0.9902 time: 0.9762s
INFO:root:Epoch: 0080 val_loss: 1.7923 val_roc: 0.9246 val_ap: 0.9250
INFO:root:Epoch: 0085 lr: 0.01 train_loss: 0.2649 train_roc: 0.9943 train_ap: 0.9893 time: 0.9780s
INFO:root:Epoch: 0085 val_loss: 1.9029 val_roc: 0.9263 val_ap: 0.9316
INFO:root:Epoch: 0090 lr: 0.01 train_loss: 0.2741 train_roc: 0.9931 train_ap: 0.9884 time: 0.9861s
INFO:root:Epoch: 0090 val_loss: 1.9680 val_roc: 0.9273 val_ap: 0.9347
INFO:root:Epoch: 0095 lr: 0.01 train_loss: 0.2937 train_roc: 0.9932 train_ap: 0.9874 time: 0.9812s
INFO:root:Epoch: 0095 val_loss: 1.9512 val_roc: 0.9299 val_ap: 0.9375
INFO:root:Epoch: 0100 lr: 0.01 train_loss: 0.2565 train_roc: 0.9963 train_ap: 0.9923 time: 0.9781s
INFO:root:Epoch: 0100 val_loss: 1.9084 val_roc: 0.9291 val_ap: 0.9369
INFO:root:Epoch: 0105 lr: 0.01 train_loss: 0.2473 train_roc: 0.9964 train_ap: 0.9945 time: 0.9786s
INFO:root:Epoch: 0105 val_loss: 1.8648 val_roc: 0.9284 val_ap: 0.9373
INFO:root:Epoch: 0110 lr: 0.01 train_loss: 0.2599 train_roc: 0.9952 train_ap: 0.9911 time: 0.9927s
INFO:root:Epoch: 0110 val_loss: 1.9815 val_roc: 0.9316 val_ap: 0.9411
INFO:root:Epoch: 0115 lr: 0.01 train_loss: 0.2511 train_roc: 0.9952 train_ap: 0.9885 time: 0.9873s
INFO:root:Epoch: 0115 val_loss: 2.2472 val_roc: 0.9335 val_ap: 0.9436
INFO:root:Epoch: 0120 lr: 0.01 train_loss: 0.2507 train_roc: 0.9968 train_ap: 0.9943 time: 0.9639s
INFO:root:Epoch: 0120 val_loss: 2.1448 val_roc: 0.9319 val_ap: 0.9425
INFO:root:Epoch: 0125 lr: 0.01 train_loss: 0.2379 train_roc: 0.9970 train_ap: 0.9925 time: 0.9623s
INFO:root:Epoch: 0125 val_loss: 2.0232 val_roc: 0.9305 val_ap: 0.9399
INFO:root:Epoch: 0130 lr: 0.01 train_loss: 0.2398 train_roc: 0.9952 train_ap: 0.9897 time: 0.9648s
INFO:root:Epoch: 0130 val_loss: 1.9801 val_roc: 0.9301 val_ap: 0.9391
INFO:root:Epoch: 0135 lr: 0.01 train_loss: 0.2449 train_roc: 0.9964 train_ap: 0.9924 time: 0.9758s
INFO:root:Epoch: 0135 val_loss: 2.0877 val_roc: 0.9343 val_ap: 0.9422
INFO:root:Epoch: 0140 lr: 0.01 train_loss: 0.2422 train_roc: 0.9961 train_ap: 0.9903 time: 0.9505s
INFO:root:Epoch: 0140 val_loss: 2.0138 val_roc: 0.9366 val_ap: 0.9439
INFO:root:Epoch: 0145 lr: 0.01 train_loss: 0.2413 train_roc: 0.9953 train_ap: 0.9885 time: 0.9713s
INFO:root:Epoch: 0145 val_loss: 1.9191 val_roc: 0.9365 val_ap: 0.9452
INFO:root:Epoch: 0150 lr: 0.01 train_loss: 0.2451 train_roc: 0.9953 train_ap: 0.9883 time: 0.9480s
INFO:root:Epoch: 0150 val_loss: 1.9114 val_roc: 0.9364 val_ap: 0.9454
INFO:root:Epoch: 0155 lr: 0.01 train_loss: 0.2257 train_roc: 0.9977 train_ap: 0.9945 time: 0.9713s
INFO:root:Epoch: 0155 val_loss: 1.8775 val_roc: 0.9330 val_ap: 0.9429
INFO:root:Epoch: 0160 lr: 0.01 train_loss: 0.2231 train_roc: 0.9977 train_ap: 0.9964 time: 0.9875s
INFO:root:Epoch: 0160 val_loss: 2.0392 val_roc: 0.9329 val_ap: 0.9430
INFO:root:Epoch: 0165 lr: 0.01 train_loss: 0.2381 train_roc: 0.9974 train_ap: 0.9949 time: 0.9789s
INFO:root:Epoch: 0165 val_loss: 2.1289 val_roc: 0.9323 val_ap: 0.9426
INFO:root:Epoch: 0170 lr: 0.01 train_loss: 0.2329 train_roc: 0.9959 train_ap: 0.9910 time: 0.9877s
INFO:root:Epoch: 0170 val_loss: 2.1756 val_roc: 0.9328 val_ap: 0.9431
INFO:root:Epoch: 0175 lr: 0.01 train_loss: 0.2267 train_roc: 0.9978 train_ap: 0.9956 time: 0.9737s
INFO:root:Epoch: 0175 val_loss: 2.0277 val_roc: 0.9320 val_ap: 0.9433
INFO:root:Epoch: 0180 lr: 0.01 train_loss: 0.2287 train_roc: 0.9971 train_ap: 0.9940 time: 0.9861s
INFO:root:Epoch: 0180 val_loss: 1.9694 val_roc: 0.9298 val_ap: 0.9422
INFO:root:Epoch: 0185 lr: 0.01 train_loss: 0.2385 train_roc: 0.9970 train_ap: 0.9953 time: 1.0193s
INFO:root:Epoch: 0185 val_loss: 2.0399 val_roc: 0.9291 val_ap: 0.9405
INFO:root:Epoch: 0190 lr: 0.01 train_loss: 0.2280 train_roc: 0.9969 train_ap: 0.9940 time: 1.0512s
INFO:root:Epoch: 0190 val_loss: 2.5002 val_roc: 0.9290 val_ap: 0.9402
INFO:root:Epoch: 0195 lr: 0.01 train_loss: 0.2425 train_roc: 0.9979 train_ap: 0.9975 time: 0.9589s
INFO:root:Epoch: 0195 val_loss: 2.2701 val_roc: 0.9302 val_ap: 0.9409
INFO:root:Epoch: 0200 lr: 0.01 train_loss: 0.2224 train_roc: 0.9983 train_ap: 0.9963 time: 0.9592s
INFO:root:Epoch: 0200 val_loss: 1.7191 val_roc: 0.9282 val_ap: 0.9403
INFO:root:Epoch: 0205 lr: 0.01 train_loss: 0.2260 train_roc: 0.9963 train_ap: 0.9914 time: 0.9698s
INFO:root:Epoch: 0205 val_loss: 1.9184 val_roc: 0.9293 val_ap: 0.9413
INFO:root:Epoch: 0210 lr: 0.01 train_loss: 0.2269 train_roc: 0.9973 train_ap: 0.9924 time: 0.9684s
INFO:root:Epoch: 0210 val_loss: 2.3100 val_roc: 0.9314 val_ap: 0.9429
INFO:root:Epoch: 0215 lr: 0.01 train_loss: 0.2274 train_roc: 0.9977 train_ap: 0.9958 time: 0.9951s
INFO:root:Epoch: 0215 val_loss: 2.1057 val_roc: 0.9287 val_ap: 0.9396
INFO:root:Epoch: 0220 lr: 0.01 train_loss: 0.2410 train_roc: 0.9966 train_ap: 0.9927 time: 0.9924s
INFO:root:Epoch: 0220 val_loss: 1.7080 val_roc: 0.9246 val_ap: 0.9347
INFO:root:Epoch: 0225 lr: 0.01 train_loss: 0.2280 train_roc: 0.9956 train_ap: 0.9901 time: 0.9848s
INFO:root:Epoch: 0225 val_loss: 2.3076 val_roc: 0.9279 val_ap: 0.9377
INFO:root:Epoch: 0230 lr: 0.01 train_loss: 0.2169 train_roc: 0.9975 train_ap: 0.9946 time: 0.9679s
INFO:root:Epoch: 0230 val_loss: 2.4732 val_roc: 0.9307 val_ap: 0.9411
INFO:root:Epoch: 0235 lr: 0.01 train_loss: 0.2280 train_roc: 0.9973 train_ap: 0.9951 time: 0.9734s
INFO:root:Epoch: 0235 val_loss: 2.1744 val_roc: 0.9288 val_ap: 0.9391
INFO:root:Epoch: 0240 lr: 0.01 train_loss: 0.2169 train_roc: 0.9970 train_ap: 0.9909 time: 0.9817s
INFO:root:Epoch: 0240 val_loss: 1.9526 val_roc: 0.9255 val_ap: 0.9361
INFO:root:Epoch: 0245 lr: 0.01 train_loss: 0.2191 train_roc: 0.9978 train_ap: 0.9961 time: 0.9777s
INFO:root:Epoch: 0245 val_loss: 2.1350 val_roc: 0.9231 val_ap: 0.9347
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 386.1914s
INFO:root:Val set results: val_loss: 1.8765 val_roc: 0.9370 val_ap: 0.9458
INFO:root:Test set results: test_loss: 1.8090 test_roc: 0.9338 test_ap: 0.9326
INFO:root:Saved model in /workspace/xiongbo/hgcn/logs/lp/2021_5_2/34
