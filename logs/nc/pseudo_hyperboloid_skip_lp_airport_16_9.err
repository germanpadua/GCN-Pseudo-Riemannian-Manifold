INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
INFO:root:LPModel(
  (encoder): HGCN(
    (layers): Sequential(
      (0): HyperbolicGraphConvolution(
        (linear): HypLinear(
          in_features=13, out_features=16, c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (agg): HypAgg(
          c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (hyp_act): HypAct(
          c_in=Parameter containing:
          tensor([-1.], requires_grad=True), c_out=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
      )
      (1): HyperbolicGraphConvolution(
        (linear): HypLinear(
          in_features=16, out_features=16, c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (agg): HypAgg(
          c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (hyp_act): HypAct(
          c_in=Parameter containing:
          tensor([-1.], requires_grad=True), c_out=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
      )
    )
  )
  (dc): FermiDiracDecoder()
)
INFO:root:Total number of parameters: 499
/workspace/anaconda3/envs/geo/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  "please use `get_last_lr()`.", UserWarning)
INFO:root:Epoch: 0005 lr: 0.01 train_loss: 2.2255 train_roc: 0.9235 train_ap: 0.9098 time: 2.9463s
INFO:root:Epoch: 0005 val_loss: 2.2147 val_roc: 0.8695 val_ap: 0.8841
INFO:root:Epoch: 0010 lr: 0.01 train_loss: 2.1467 train_roc: 0.9234 train_ap: 0.9146 time: 3.0503s
INFO:root:Epoch: 0010 val_loss: 2.1961 val_roc: 0.8783 val_ap: 0.8857
INFO:root:Epoch: 0015 lr: 0.01 train_loss: 2.1467 train_roc: 0.9149 train_ap: 0.9063 time: 3.1311s
INFO:root:Epoch: 0015 val_loss: 2.1799 val_roc: 0.8827 val_ap: 0.8880
INFO:root:Epoch: 0020 lr: 0.01 train_loss: 2.1527 train_roc: 0.9206 train_ap: 0.9096 time: 3.0848s
INFO:root:Epoch: 0020 val_loss: 2.1676 val_roc: 0.8663 val_ap: 0.8861
INFO:root:Epoch: 0025 lr: 0.01 train_loss: 2.1816 train_roc: 0.9065 train_ap: 0.8915 time: 3.0750s
INFO:root:Epoch: 0025 val_loss: 2.0999 val_roc: 0.8666 val_ap: 0.8807
INFO:root:Epoch: 0030 lr: 0.01 train_loss: 2.1378 train_roc: 0.9318 train_ap: 0.9222 time: 3.0864s
INFO:root:Epoch: 0030 val_loss: 2.0140 val_roc: 0.8572 val_ap: 0.8698
INFO:root:Epoch: 0035 lr: 0.01 train_loss: 2.0956 train_roc: 0.9109 train_ap: 0.8891 time: 3.1046s
INFO:root:Epoch: 0035 val_loss: 1.8740 val_roc: 0.8585 val_ap: 0.8707
INFO:root:Epoch: 0040 lr: 0.01 train_loss: 1.8239 train_roc: 0.9010 train_ap: 0.8917 time: 3.1003s
INFO:root:Epoch: 0040 val_loss: 1.6056 val_roc: 0.8664 val_ap: 0.8765
INFO:root:Epoch: 0045 lr: 0.01 train_loss: 1.7366 train_roc: 0.9244 train_ap: 0.9142 time: 3.0942s
INFO:root:Epoch: 0045 val_loss: 1.2729 val_roc: 0.8819 val_ap: 0.8831
INFO:root:Epoch: 0050 lr: 0.01 train_loss: 1.2209 train_roc: 0.9344 train_ap: 0.9213 time: 3.2448s
INFO:root:Epoch: 0050 val_loss: 1.0864 val_roc: 0.8735 val_ap: 0.8633
INFO:root:Epoch: 0055 lr: 0.01 train_loss: 0.8662 train_roc: 0.9179 train_ap: 0.9032 time: 3.0997s
INFO:root:Epoch: 0055 val_loss: 1.2264 val_roc: 0.8707 val_ap: 0.8676
INFO:root:Epoch: 0060 lr: 0.01 train_loss: 0.7131 train_roc: 0.9288 train_ap: 0.9140 time: 2.0666s
INFO:root:Epoch: 0060 val_loss: 1.9794 val_roc: 0.8711 val_ap: 0.8641
INFO:root:Epoch: 0065 lr: 0.01 train_loss: 1.2851 train_roc: 0.9239 train_ap: 0.9159 time: 2.0572s
INFO:root:Epoch: 0065 val_loss: 2.8671 val_roc: 0.8795 val_ap: 0.8753
INFO:root:Epoch: 0070 lr: 0.01 train_loss: 0.7915 train_roc: 0.9243 train_ap: 0.9110 time: 2.2892s
INFO:root:Epoch: 0070 val_loss: 2.1368 val_roc: 0.8775 val_ap: 0.8759
INFO:root:Epoch: 0075 lr: 0.01 train_loss: 1.1005 train_roc: 0.8997 train_ap: 0.8890 time: 1.8955s
INFO:root:Epoch: 0075 val_loss: 1.6328 val_roc: 0.8815 val_ap: 0.8796
INFO:root:Epoch: 0080 lr: 0.01 train_loss: 0.7178 train_roc: 0.9365 train_ap: 0.9220 time: 2.0323s
INFO:root:Epoch: 0080 val_loss: 1.3978 val_roc: 0.8973 val_ap: 0.9023
INFO:root:Epoch: 0085 lr: 0.01 train_loss: 0.7271 train_roc: 0.9271 train_ap: 0.9119 time: 2.0432s
INFO:root:Epoch: 0085 val_loss: 1.3248 val_roc: 0.9044 val_ap: 0.9109
INFO:root:Epoch: 0090 lr: 0.01 train_loss: 0.9270 train_roc: 0.9174 train_ap: 0.8957 time: 1.9895s
INFO:root:Epoch: 0090 val_loss: 1.1759 val_roc: 0.9100 val_ap: 0.9163
INFO:root:Epoch: 0095 lr: 0.01 train_loss: 0.6919 train_roc: 0.9442 train_ap: 0.9363 time: 2.0520s
INFO:root:Epoch: 0095 val_loss: 1.0718 val_roc: 0.9123 val_ap: 0.9148
INFO:root:Epoch: 0100 lr: 0.01 train_loss: 0.7881 train_roc: 0.9381 train_ap: 0.9267 time: 2.0165s
INFO:root:Epoch: 0100 val_loss: 1.1217 val_roc: 0.9148 val_ap: 0.9195
INFO:root:Epoch: 0105 lr: 0.01 train_loss: 0.5747 train_roc: 0.9543 train_ap: 0.9418 time: 2.0313s
INFO:root:Epoch: 0105 val_loss: 1.4721 val_roc: 0.9163 val_ap: 0.9155
INFO:root:Epoch: 0110 lr: 0.01 train_loss: 0.6058 train_roc: 0.9559 train_ap: 0.9447 time: 1.8872s
INFO:root:Epoch: 0110 val_loss: 1.5152 val_roc: 0.9175 val_ap: 0.9176
INFO:root:Epoch: 0115 lr: 0.01 train_loss: 0.6684 train_roc: 0.9389 train_ap: 0.9250 time: 1.9868s
INFO:root:Epoch: 0115 val_loss: 1.4484 val_roc: 0.9182 val_ap: 0.9228
INFO:root:Epoch: 0120 lr: 0.01 train_loss: 0.7123 train_roc: 0.9453 train_ap: 0.9344 time: 2.1619s
INFO:root:Epoch: 0120 val_loss: 1.3606 val_roc: 0.9191 val_ap: 0.9234
INFO:root:Epoch: 0125 lr: 0.01 train_loss: 0.6738 train_roc: 0.9429 train_ap: 0.9303 time: 3.0073s
INFO:root:Epoch: 0125 val_loss: 1.4355 val_roc: 0.9212 val_ap: 0.9257
INFO:root:Epoch: 0130 lr: 0.01 train_loss: 0.6590 train_roc: 0.9488 train_ap: 0.9361 time: 3.2462s
INFO:root:Epoch: 0130 val_loss: 1.3096 val_roc: 0.9223 val_ap: 0.9259
INFO:root:Epoch: 0135 lr: 0.01 train_loss: 0.6526 train_roc: 0.9483 train_ap: 0.9420 time: 3.1132s
INFO:root:Epoch: 0135 val_loss: 1.0854 val_roc: 0.9230 val_ap: 0.9276
INFO:root:Epoch: 0140 lr: 0.01 train_loss: 0.6247 train_roc: 0.9596 train_ap: 0.9495 time: 3.2500s
INFO:root:Epoch: 0140 val_loss: 1.0904 val_roc: 0.9223 val_ap: 0.9264
INFO:root:Epoch: 0145 lr: 0.01 train_loss: 0.6362 train_roc: 0.9610 train_ap: 0.9517 time: 3.0759s
INFO:root:Epoch: 0145 val_loss: 1.0841 val_roc: 0.9246 val_ap: 0.9299
INFO:root:Epoch: 0150 lr: 0.01 train_loss: 0.6993 train_roc: 0.9538 train_ap: 0.9452 time: 3.1729s
INFO:root:Epoch: 0150 val_loss: 1.2503 val_roc: 0.9247 val_ap: 0.9303
INFO:root:Epoch: 0155 lr: 0.01 train_loss: 0.5684 train_roc: 0.9573 train_ap: 0.9464 time: 3.1892s
INFO:root:Epoch: 0155 val_loss: 1.1419 val_roc: 0.9214 val_ap: 0.9285
INFO:root:Epoch: 0160 lr: 0.01 train_loss: 0.6088 train_roc: 0.9540 train_ap: 0.9431 time: 3.1037s
INFO:root:Epoch: 0160 val_loss: 1.0538 val_roc: 0.9185 val_ap: 0.9275
INFO:root:Epoch: 0165 lr: 0.01 train_loss: 0.5600 train_roc: 0.9597 train_ap: 0.9513 time: 3.1944s
INFO:root:Epoch: 0165 val_loss: 1.0538 val_roc: 0.9172 val_ap: 0.9270
INFO:root:Epoch: 0170 lr: 0.01 train_loss: 0.7839 train_roc: 0.9510 train_ap: 0.9395 time: 3.0443s
INFO:root:Epoch: 0170 val_loss: 1.1554 val_roc: 0.9169 val_ap: 0.9266
INFO:root:Epoch: 0175 lr: 0.01 train_loss: 0.5260 train_roc: 0.9623 train_ap: 0.9513 time: 3.0064s
INFO:root:Epoch: 0175 val_loss: 1.0791 val_roc: 0.9160 val_ap: 0.9261
INFO:root:Epoch: 0180 lr: 0.01 train_loss: 0.6598 train_roc: 0.9599 train_ap: 0.9496 time: 3.2168s
INFO:root:Epoch: 0180 val_loss: 1.1469 val_roc: 0.9159 val_ap: 0.9260
INFO:root:Epoch: 0185 lr: 0.01 train_loss: 0.5975 train_roc: 0.9633 train_ap: 0.9523 time: 3.1892s
INFO:root:Epoch: 0185 val_loss: 1.2121 val_roc: 0.9159 val_ap: 0.9260
INFO:root:Epoch: 0190 lr: 0.01 train_loss: 0.6446 train_roc: 0.9490 train_ap: 0.9381 time: 3.1172s
INFO:root:Epoch: 0190 val_loss: 1.2521 val_roc: 0.9153 val_ap: 0.9261
INFO:root:Epoch: 0195 lr: 0.01 train_loss: 0.5726 train_roc: 0.9593 train_ap: 0.9477 time: 3.0758s
INFO:root:Epoch: 0195 val_loss: 1.0381 val_roc: 0.9153 val_ap: 0.9263
INFO:root:Epoch: 0200 lr: 0.01 train_loss: 0.8057 train_roc: 0.9430 train_ap: 0.9299 time: 3.0895s
INFO:root:Epoch: 0200 val_loss: 0.9617 val_roc: 0.9152 val_ap: 0.9266
INFO:root:Epoch: 0205 lr: 0.01 train_loss: 0.5792 train_roc: 0.9579 train_ap: 0.9456 time: 3.0774s
INFO:root:Epoch: 0205 val_loss: 1.0013 val_roc: 0.9156 val_ap: 0.9266
INFO:root:Epoch: 0210 lr: 0.01 train_loss: 0.7579 train_roc: 0.9587 train_ap: 0.9483 time: 3.0732s
INFO:root:Epoch: 0210 val_loss: 1.2158 val_roc: 0.9155 val_ap: 0.9269
INFO:root:Epoch: 0215 lr: 0.01 train_loss: 0.5612 train_roc: 0.9584 train_ap: 0.9475 time: 3.1943s
INFO:root:Epoch: 0215 val_loss: 1.1636 val_roc: 0.9147 val_ap: 0.9275
INFO:root:Epoch: 0220 lr: 0.01 train_loss: 0.6613 train_roc: 0.9545 train_ap: 0.9457 time: 3.0527s
INFO:root:Epoch: 0220 val_loss: 1.0344 val_roc: 0.9152 val_ap: 0.9288
INFO:root:Epoch: 0225 lr: 0.01 train_loss: 0.5761 train_roc: 0.9573 train_ap: 0.9472 time: 3.2469s
INFO:root:Epoch: 0225 val_loss: 1.0296 val_roc: 0.9133 val_ap: 0.9283
INFO:root:Epoch: 0230 lr: 0.01 train_loss: 0.5696 train_roc: 0.9610 train_ap: 0.9520 time: 3.2385s
INFO:root:Epoch: 0230 val_loss: 1.0688 val_roc: 0.9129 val_ap: 0.9284
INFO:root:Epoch: 0235 lr: 0.01 train_loss: 0.6319 train_roc: 0.9560 train_ap: 0.9485 time: 3.1039s
INFO:root:Epoch: 0235 val_loss: 1.1741 val_roc: 0.9120 val_ap: 0.9280
INFO:root:Epoch: 0240 lr: 0.01 train_loss: 0.6348 train_roc: 0.9527 train_ap: 0.9439 time: 3.0482s
INFO:root:Epoch: 0240 val_loss: 1.2723 val_roc: 0.9115 val_ap: 0.9277
INFO:root:Epoch: 0245 lr: 0.01 train_loss: 0.5801 train_roc: 0.9616 train_ap: 0.9532 time: 3.1029s
INFO:root:Epoch: 0245 val_loss: 1.3091 val_roc: 0.9116 val_ap: 0.9279
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 871.4395s
INFO:root:Val set results: val_loss: 1.1910 val_roc: 0.9252 val_ap: 0.9306
INFO:root:Test set results: test_loss: 1.1869 test_roc: 0.9245 test_ap: 0.9176
INFO:root:Saved model in /workspace/xiongbo/hgcn/logs/lp/2021_5_3/12
