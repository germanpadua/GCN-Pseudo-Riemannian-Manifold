INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
INFO:root:Num classes: 6
INFO:root:NCModel(
  (encoder): HGCN(
    (layers): Sequential(
      (0): HyperbolicGraphConvolution(
        (linear): HypLinear(
          in_features=3704, out_features=16, c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (agg): HypAgg(
          c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (hyp_act): HypAct(
          c_in=Parameter containing:
          tensor([-1.], requires_grad=True), c_out=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
      )
    )
  )
  (decoder): LinearDecoder(
    in_features=16, out_features=6, bias=1, c=Parameter containing:
    tensor([-1.], requires_grad=True)
    (cls): Linear(
      (linear): Linear(in_features=16, out_features=6, bias=True)
    )
  )
)
INFO:root:Total number of parameters: 59384
/workspace/anaconda3/envs/geo/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  "please use `get_last_lr()`.", UserWarning)
INFO:root:Epoch: 0005 lr: 0.01 train_loss: 1.6218 train_acc: 0.4333 train_f1: 0.4333 time: 0.5374s
INFO:root:Epoch: 0005 val_loss: 1.7057 val_acc: 0.3260 val_f1: 0.3260
INFO:root:Epoch: 0010 lr: 0.01 train_loss: 1.4781 train_acc: 0.5667 train_f1: 0.5667 time: 0.4922s
INFO:root:Epoch: 0010 val_loss: 1.6517 val_acc: 0.4840 val_f1: 0.4840
INFO:root:Epoch: 0015 lr: 0.01 train_loss: 1.4131 train_acc: 0.5417 train_f1: 0.5417 time: 0.5341s
INFO:root:Epoch: 0015 val_loss: 1.6039 val_acc: 0.5320 val_f1: 0.5320
INFO:root:Epoch: 0020 lr: 0.01 train_loss: 1.3233 train_acc: 0.5500 train_f1: 0.5500 time: 0.4927s
INFO:root:Epoch: 0020 val_loss: 1.5514 val_acc: 0.5580 val_f1: 0.5580
INFO:root:Epoch: 0025 lr: 0.01 train_loss: 1.2301 train_acc: 0.5500 train_f1: 0.5500 time: 0.4907s
INFO:root:Epoch: 0025 val_loss: 1.5167 val_acc: 0.5520 val_f1: 0.5520
INFO:root:Epoch: 0030 lr: 0.01 train_loss: 1.1494 train_acc: 0.5833 train_f1: 0.5833 time: 0.4930s
INFO:root:Epoch: 0030 val_loss: 1.4779 val_acc: 0.5580 val_f1: 0.5580
INFO:root:Epoch: 0035 lr: 0.01 train_loss: 1.1153 train_acc: 0.5583 train_f1: 0.5583 time: 0.4931s
INFO:root:Epoch: 0035 val_loss: 1.4510 val_acc: 0.5580 val_f1: 0.5580
INFO:root:Epoch: 0040 lr: 0.01 train_loss: 1.0228 train_acc: 0.6250 train_f1: 0.6250 time: 0.4979s
INFO:root:Epoch: 0040 val_loss: 1.4208 val_acc: 0.5760 val_f1: 0.5760
INFO:root:Epoch: 0045 lr: 0.01 train_loss: 1.0535 train_acc: 0.6000 train_f1: 0.6000 time: 0.4919s
INFO:root:Epoch: 0045 val_loss: 1.3712 val_acc: 0.5940 val_f1: 0.5940
INFO:root:Epoch: 0050 lr: 0.01 train_loss: 1.0633 train_acc: 0.5917 train_f1: 0.5917 time: 0.4948s
INFO:root:Epoch: 0050 val_loss: 1.3399 val_acc: 0.6000 val_f1: 0.6000
INFO:root:Epoch: 0055 lr: 0.01 train_loss: 0.9567 train_acc: 0.6333 train_f1: 0.6333 time: 0.4952s
INFO:root:Epoch: 0055 val_loss: 1.3345 val_acc: 0.5840 val_f1: 0.5840
INFO:root:Epoch: 0060 lr: 0.01 train_loss: 0.9485 train_acc: 0.6500 train_f1: 0.6500 time: 0.4907s
INFO:root:Epoch: 0060 val_loss: 1.3249 val_acc: 0.5720 val_f1: 0.5720
INFO:root:Epoch: 0065 lr: 0.01 train_loss: 0.8912 train_acc: 0.6667 train_f1: 0.6667 time: 0.4911s
INFO:root:Epoch: 0065 val_loss: 1.2985 val_acc: 0.5860 val_f1: 0.5860
INFO:root:Epoch: 0070 lr: 0.01 train_loss: 0.8118 train_acc: 0.6500 train_f1: 0.6500 time: 0.4949s
INFO:root:Epoch: 0070 val_loss: 1.2787 val_acc: 0.5920 val_f1: 0.5920
INFO:root:Epoch: 0075 lr: 0.01 train_loss: 0.7764 train_acc: 0.6250 train_f1: 0.6250 time: 0.4952s
INFO:root:Epoch: 0075 val_loss: 1.2723 val_acc: 0.5960 val_f1: 0.5960
INFO:root:Epoch: 0080 lr: 0.01 train_loss: 0.7202 train_acc: 0.6917 train_f1: 0.6917 time: 0.4930s
INFO:root:Epoch: 0080 val_loss: 1.2601 val_acc: 0.5920 val_f1: 0.5920
INFO:root:Epoch: 0085 lr: 0.01 train_loss: 0.7057 train_acc: 0.6667 train_f1: 0.6667 time: 0.4956s
INFO:root:Epoch: 0085 val_loss: 1.2466 val_acc: 0.6020 val_f1: 0.6020
INFO:root:Epoch: 0090 lr: 0.01 train_loss: 0.7118 train_acc: 0.7167 train_f1: 0.7167 time: 0.4938s
INFO:root:Epoch: 0090 val_loss: 1.2362 val_acc: 0.5920 val_f1: 0.5920
INFO:root:Epoch: 0095 lr: 0.01 train_loss: 0.5905 train_acc: 0.7250 train_f1: 0.7250 time: 0.4955s
INFO:root:Epoch: 0095 val_loss: 1.2123 val_acc: 0.6080 val_f1: 0.6080
INFO:root:Epoch: 0100 lr: 0.01 train_loss: 0.7002 train_acc: 0.7333 train_f1: 0.7333 time: 0.4896s
INFO:root:Epoch: 0100 val_loss: 1.1932 val_acc: 0.6140 val_f1: 0.6140
INFO:root:Epoch: 0105 lr: 0.01 train_loss: 0.7849 train_acc: 0.6333 train_f1: 0.6333 time: 0.4922s
INFO:root:Epoch: 0105 val_loss: 1.2079 val_acc: 0.6000 val_f1: 0.6000
INFO:root:Epoch: 0110 lr: 0.01 train_loss: 0.7479 train_acc: 0.6333 train_f1: 0.6333 time: 0.4935s
INFO:root:Epoch: 0110 val_loss: 1.2306 val_acc: 0.5920 val_f1: 0.5920
INFO:root:Epoch: 0115 lr: 0.01 train_loss: 0.6170 train_acc: 0.7083 train_f1: 0.7083 time: 0.4939s
INFO:root:Epoch: 0115 val_loss: 1.2087 val_acc: 0.6000 val_f1: 0.6000
INFO:root:Epoch: 0120 lr: 0.01 train_loss: 0.6845 train_acc: 0.6583 train_f1: 0.6583 time: 0.4948s
INFO:root:Epoch: 0120 val_loss: 1.1920 val_acc: 0.6000 val_f1: 0.6000
INFO:root:Epoch: 0125 lr: 0.01 train_loss: 0.7614 train_acc: 0.6500 train_f1: 0.6500 time: 0.4886s
INFO:root:Epoch: 0125 val_loss: 1.2049 val_acc: 0.5900 val_f1: 0.5900
INFO:root:Epoch: 0130 lr: 0.01 train_loss: 0.7239 train_acc: 0.6500 train_f1: 0.6500 time: 0.4951s
INFO:root:Epoch: 0130 val_loss: 1.1966 val_acc: 0.5940 val_f1: 0.5940
INFO:root:Epoch: 0135 lr: 0.01 train_loss: 0.6726 train_acc: 0.6417 train_f1: 0.6417 time: 0.4925s
INFO:root:Epoch: 0135 val_loss: 1.1970 val_acc: 0.5920 val_f1: 0.5920
INFO:root:Epoch: 0140 lr: 0.01 train_loss: 0.5956 train_acc: 0.7000 train_f1: 0.7000 time: 0.4944s
INFO:root:Epoch: 0140 val_loss: 1.1969 val_acc: 0.5940 val_f1: 0.5940
INFO:root:Epoch: 0145 lr: 0.01 train_loss: 0.5843 train_acc: 0.7250 train_f1: 0.7250 time: 0.4946s
INFO:root:Epoch: 0145 val_loss: 1.1859 val_acc: 0.5960 val_f1: 0.5960
INFO:root:Epoch: 0150 lr: 0.01 train_loss: 0.6790 train_acc: 0.6417 train_f1: 0.6417 time: 0.4938s
INFO:root:Epoch: 0150 val_loss: 1.1797 val_acc: 0.5940 val_f1: 0.5940
INFO:root:Epoch: 0155 lr: 0.01 train_loss: 0.6594 train_acc: 0.6583 train_f1: 0.6583 time: 0.4940s
INFO:root:Epoch: 0155 val_loss: 1.1928 val_acc: 0.5820 val_f1: 0.5820
INFO:root:Epoch: 0160 lr: 0.01 train_loss: 0.7207 train_acc: 0.6167 train_f1: 0.6167 time: 0.4946s
INFO:root:Epoch: 0160 val_loss: 1.1980 val_acc: 0.5880 val_f1: 0.5880
INFO:root:Epoch: 0165 lr: 0.01 train_loss: 0.6376 train_acc: 0.6417 train_f1: 0.6417 time: 0.4939s
INFO:root:Epoch: 0165 val_loss: 1.1924 val_acc: 0.5780 val_f1: 0.5780
INFO:root:Epoch: 0170 lr: 0.01 train_loss: 0.6083 train_acc: 0.6917 train_f1: 0.6917 time: 0.4977s
INFO:root:Epoch: 0170 val_loss: 1.1950 val_acc: 0.5860 val_f1: 0.5860
INFO:root:Epoch: 0175 lr: 0.01 train_loss: 0.6664 train_acc: 0.6667 train_f1: 0.6667 time: 0.4975s
INFO:root:Epoch: 0175 val_loss: 1.1940 val_acc: 0.6000 val_f1: 0.6000
INFO:root:Epoch: 0180 lr: 0.01 train_loss: 0.7589 train_acc: 0.6000 train_f1: 0.6000 time: 0.5312s
INFO:root:Epoch: 0180 val_loss: 1.1832 val_acc: 0.6020 val_f1: 0.6020
INFO:root:Epoch: 0185 lr: 0.01 train_loss: 0.5659 train_acc: 0.7000 train_f1: 0.7000 time: 0.4966s
INFO:root:Epoch: 0185 val_loss: 1.1899 val_acc: 0.5920 val_f1: 0.5920
INFO:root:Epoch: 0190 lr: 0.01 train_loss: 0.6429 train_acc: 0.6250 train_f1: 0.6250 time: 0.4916s
INFO:root:Epoch: 0190 val_loss: 1.1813 val_acc: 0.5940 val_f1: 0.5940
INFO:root:Epoch: 0195 lr: 0.01 train_loss: 0.6016 train_acc: 0.7167 train_f1: 0.7167 time: 0.4957s
INFO:root:Epoch: 0195 val_loss: 1.1607 val_acc: 0.6080 val_f1: 0.6080
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 161.5549s
INFO:root:Val set results: val_loss: 1.2006 val_acc: 0.6160 val_f1: 0.6160
INFO:root:Test set results: test_loss: 1.1813 test_acc: 0.6060 test_f1: 0.6060
INFO:root:Saved model in /workspace/xiongbo/hgcn/logs/nc/2021_5_3/0
