INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
INFO:root:LPModel(
  (encoder): HGCN(
    (layers): Sequential(
      (0): HyperbolicGraphConvolution(
        (linear): HypLinear(
          in_features=3704, out_features=16, c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (agg): HypAgg(
          c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (hyp_act): HypAct(
          c_in=Parameter containing:
          tensor([-1.], requires_grad=True), c_out=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
      )
      (1): HyperbolicGraphConvolution(
        (linear): HypLinear(
          in_features=16, out_features=16, c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (agg): HypAgg(
          c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (hyp_act): HypAct(
          c_in=Parameter containing:
          tensor([-1.], requires_grad=True), c_out=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
      )
    )
  )
  (dc): FermiDiracDecoder()
)
INFO:root:Total number of parameters: 59555
/workspace/anaconda3/envs/geo/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  "please use `get_last_lr()`.", UserWarning)
INFO:root:Epoch: 0005 lr: 0.01 train_loss: 1.8661 train_roc: 0.7910 train_ap: 0.7822 time: 0.9812s
INFO:root:Epoch: 0005 val_loss: 1.7669 val_roc: 0.8308 val_ap: 0.8353
INFO:root:Epoch: 0010 lr: 0.01 train_loss: 1.7217 train_roc: 0.8908 train_ap: 0.8814 time: 0.9417s
INFO:root:Epoch: 0010 val_loss: 1.6028 val_roc: 0.8440 val_ap: 0.8565
INFO:root:Epoch: 0015 lr: 0.01 train_loss: 1.5107 train_roc: 0.9354 train_ap: 0.9253 time: 0.9613s
INFO:root:Epoch: 0015 val_loss: 1.3690 val_roc: 0.8694 val_ap: 0.8779
INFO:root:Epoch: 0020 lr: 0.01 train_loss: 1.3179 train_roc: 0.9482 train_ap: 0.9402 time: 0.9259s
INFO:root:Epoch: 0020 val_loss: 1.1305 val_roc: 0.8696 val_ap: 0.8705
INFO:root:Epoch: 0025 lr: 0.01 train_loss: 1.0195 train_roc: 0.9632 train_ap: 0.9551 time: 0.9676s
INFO:root:Epoch: 0025 val_loss: 0.9379 val_roc: 0.8773 val_ap: 0.8844
INFO:root:Epoch: 0030 lr: 0.01 train_loss: 0.7975 train_roc: 0.9663 train_ap: 0.9580 time: 0.9653s
INFO:root:Epoch: 0030 val_loss: 0.9319 val_roc: 0.8796 val_ap: 0.8896
INFO:root:Epoch: 0035 lr: 0.01 train_loss: 0.5110 train_roc: 0.9773 train_ap: 0.9731 time: 0.9572s
INFO:root:Epoch: 0035 val_loss: 1.2347 val_roc: 0.8843 val_ap: 0.8967
INFO:root:Epoch: 0040 lr: 0.01 train_loss: 0.4292 train_roc: 0.9820 train_ap: 0.9742 time: 0.9831s
INFO:root:Epoch: 0040 val_loss: 1.7871 val_roc: 0.8968 val_ap: 0.9096
INFO:root:Epoch: 0045 lr: 0.01 train_loss: 0.4106 train_roc: 0.9833 train_ap: 0.9759 time: 0.9973s
INFO:root:Epoch: 0045 val_loss: 2.0654 val_roc: 0.9058 val_ap: 0.9161
INFO:root:Epoch: 0050 lr: 0.01 train_loss: 0.3592 train_roc: 0.9876 train_ap: 0.9826 time: 1.0063s
INFO:root:Epoch: 0050 val_loss: 1.8167 val_roc: 0.9111 val_ap: 0.9199
INFO:root:Epoch: 0055 lr: 0.01 train_loss: 0.3298 train_roc: 0.9903 train_ap: 0.9866 time: 1.0257s
INFO:root:Epoch: 0055 val_loss: 1.6101 val_roc: 0.9195 val_ap: 0.9265
INFO:root:Epoch: 0060 lr: 0.01 train_loss: 0.3128 train_roc: 0.9917 train_ap: 0.9870 time: 1.0070s
INFO:root:Epoch: 0060 val_loss: 1.5115 val_roc: 0.9252 val_ap: 0.9310
INFO:root:Epoch: 0065 lr: 0.01 train_loss: 0.2983 train_roc: 0.9919 train_ap: 0.9852 time: 0.9896s
INFO:root:Epoch: 0065 val_loss: 1.5455 val_roc: 0.9269 val_ap: 0.9338
INFO:root:Epoch: 0070 lr: 0.01 train_loss: 0.2953 train_roc: 0.9939 train_ap: 0.9908 time: 0.9851s
INFO:root:Epoch: 0070 val_loss: 1.6894 val_roc: 0.9266 val_ap: 0.9354
INFO:root:Epoch: 0075 lr: 0.01 train_loss: 0.2854 train_roc: 0.9941 train_ap: 0.9918 time: 0.9671s
INFO:root:Epoch: 0075 val_loss: 1.8681 val_roc: 0.9242 val_ap: 0.9341
INFO:root:Epoch: 0080 lr: 0.01 train_loss: 0.2624 train_roc: 0.9955 train_ap: 0.9908 time: 0.9837s
INFO:root:Epoch: 0080 val_loss: 1.7929 val_roc: 0.9211 val_ap: 0.9313
INFO:root:Epoch: 0085 lr: 0.01 train_loss: 0.2651 train_roc: 0.9952 train_ap: 0.9905 time: 0.9818s
INFO:root:Epoch: 0085 val_loss: 1.8840 val_roc: 0.9217 val_ap: 0.9327
INFO:root:Epoch: 0090 lr: 0.01 train_loss: 0.2597 train_roc: 0.9951 train_ap: 0.9910 time: 0.9824s
INFO:root:Epoch: 0090 val_loss: 1.9670 val_roc: 0.9236 val_ap: 0.9346
INFO:root:Epoch: 0095 lr: 0.01 train_loss: 0.2938 train_roc: 0.9940 train_ap: 0.9890 time: 0.9765s
INFO:root:Epoch: 0095 val_loss: 1.9558 val_roc: 0.9270 val_ap: 0.9371
INFO:root:Epoch: 0100 lr: 0.01 train_loss: 0.2491 train_roc: 0.9960 train_ap: 0.9906 time: 1.0067s
INFO:root:Epoch: 0100 val_loss: 1.8606 val_roc: 0.9302 val_ap: 0.9386
INFO:root:Epoch: 0105 lr: 0.01 train_loss: 0.2432 train_roc: 0.9978 train_ap: 0.9965 time: 0.9623s
INFO:root:Epoch: 0105 val_loss: 1.7349 val_roc: 0.9325 val_ap: 0.9390
INFO:root:Epoch: 0110 lr: 0.01 train_loss: 0.2797 train_roc: 0.9938 train_ap: 0.9897 time: 0.9960s
INFO:root:Epoch: 0110 val_loss: 1.8250 val_roc: 0.9343 val_ap: 0.9392
INFO:root:Epoch: 0115 lr: 0.01 train_loss: 0.2491 train_roc: 0.9958 train_ap: 0.9898 time: 0.9881s
INFO:root:Epoch: 0115 val_loss: 2.0292 val_roc: 0.9369 val_ap: 0.9424
INFO:root:Epoch: 0120 lr: 0.01 train_loss: 0.2644 train_roc: 0.9965 train_ap: 0.9933 time: 0.9825s
INFO:root:Epoch: 0120 val_loss: 2.0188 val_roc: 0.9336 val_ap: 0.9388
INFO:root:Epoch: 0125 lr: 0.01 train_loss: 0.2338 train_roc: 0.9971 train_ap: 0.9928 time: 0.9749s
INFO:root:Epoch: 0125 val_loss: 1.9304 val_roc: 0.9299 val_ap: 0.9348
INFO:root:Epoch: 0130 lr: 0.01 train_loss: 0.2448 train_roc: 0.9959 train_ap: 0.9900 time: 0.9601s
INFO:root:Epoch: 0130 val_loss: 1.8711 val_roc: 0.9276 val_ap: 0.9322
INFO:root:Epoch: 0135 lr: 0.01 train_loss: 0.2332 train_roc: 0.9967 train_ap: 0.9921 time: 0.9467s
INFO:root:Epoch: 0135 val_loss: 2.0717 val_roc: 0.9298 val_ap: 0.9356
INFO:root:Epoch: 0140 lr: 0.01 train_loss: 0.2311 train_roc: 0.9966 train_ap: 0.9910 time: 0.9780s
INFO:root:Epoch: 0140 val_loss: 2.1304 val_roc: 0.9327 val_ap: 0.9386
INFO:root:Epoch: 0145 lr: 0.01 train_loss: 0.2433 train_roc: 0.9959 train_ap: 0.9892 time: 1.0060s
INFO:root:Epoch: 0145 val_loss: 2.0179 val_roc: 0.9365 val_ap: 0.9420
INFO:root:Epoch: 0150 lr: 0.01 train_loss: 0.2363 train_roc: 0.9957 train_ap: 0.9886 time: 0.9682s
INFO:root:Epoch: 0150 val_loss: 1.9027 val_roc: 0.9358 val_ap: 0.9415
INFO:root:Epoch: 0155 lr: 0.01 train_loss: 0.2225 train_roc: 0.9979 train_ap: 0.9959 time: 0.9491s
INFO:root:Epoch: 0155 val_loss: 1.7271 val_roc: 0.9327 val_ap: 0.9387
INFO:root:Epoch: 0160 lr: 0.01 train_loss: 0.2161 train_roc: 0.9976 train_ap: 0.9959 time: 0.9658s
INFO:root:Epoch: 0160 val_loss: 2.0792 val_roc: 0.9313 val_ap: 0.9377
INFO:root:Epoch: 0165 lr: 0.01 train_loss: 0.2262 train_roc: 0.9970 train_ap: 0.9934 time: 0.9550s
INFO:root:Epoch: 0165 val_loss: 2.1948 val_roc: 0.9339 val_ap: 0.9399
INFO:root:Epoch: 0170 lr: 0.01 train_loss: 0.2274 train_roc: 0.9963 train_ap: 0.9916 time: 0.9807s
INFO:root:Epoch: 0170 val_loss: 2.2263 val_roc: 0.9366 val_ap: 0.9423
INFO:root:Epoch: 0175 lr: 0.01 train_loss: 0.2286 train_roc: 0.9977 train_ap: 0.9956 time: 0.9360s
INFO:root:Epoch: 0175 val_loss: 1.9261 val_roc: 0.9370 val_ap: 0.9429
INFO:root:Epoch: 0180 lr: 0.01 train_loss: 0.2213 train_roc: 0.9978 train_ap: 0.9956 time: 0.9550s
INFO:root:Epoch: 0180 val_loss: 1.8223 val_roc: 0.9348 val_ap: 0.9417
INFO:root:Epoch: 0185 lr: 0.01 train_loss: 0.2376 train_roc: 0.9964 train_ap: 0.9935 time: 0.9843s
INFO:root:Epoch: 0185 val_loss: 2.1157 val_roc: 0.9341 val_ap: 0.9409
INFO:root:Epoch: 0190 lr: 0.01 train_loss: 0.2228 train_roc: 0.9980 train_ap: 0.9958 time: 0.9460s
INFO:root:Epoch: 0190 val_loss: 2.3453 val_roc: 0.9313 val_ap: 0.9400
INFO:root:Epoch: 0195 lr: 0.01 train_loss: 0.2199 train_roc: 0.9982 train_ap: 0.9978 time: 0.9517s
INFO:root:Epoch: 0195 val_loss: 1.9756 val_roc: 0.9300 val_ap: 0.9389
INFO:root:Epoch: 0200 lr: 0.01 train_loss: 0.2266 train_roc: 0.9981 train_ap: 0.9960 time: 0.9992s
INFO:root:Epoch: 0200 val_loss: 1.5925 val_roc: 0.9308 val_ap: 0.9393
INFO:root:Epoch: 0205 lr: 0.01 train_loss: 0.2240 train_roc: 0.9955 train_ap: 0.9889 time: 1.0021s
INFO:root:Epoch: 0205 val_loss: 2.0160 val_roc: 0.9353 val_ap: 0.9423
INFO:root:Epoch: 0210 lr: 0.01 train_loss: 0.2397 train_roc: 0.9971 train_ap: 0.9920 time: 0.9995s
INFO:root:Epoch: 0210 val_loss: 2.2562 val_roc: 0.9355 val_ap: 0.9419
INFO:root:Epoch: 0215 lr: 0.01 train_loss: 0.2163 train_roc: 0.9985 train_ap: 0.9972 time: 1.0393s
INFO:root:Epoch: 0215 val_loss: 2.0106 val_roc: 0.9296 val_ap: 0.9360
INFO:root:Epoch: 0220 lr: 0.01 train_loss: 0.2555 train_roc: 0.9966 train_ap: 0.9923 time: 0.9890s
INFO:root:Epoch: 0220 val_loss: 1.7223 val_roc: 0.9218 val_ap: 0.9271
INFO:root:Epoch: 0225 lr: 0.01 train_loss: 0.2226 train_roc: 0.9971 train_ap: 0.9930 time: 1.0162s
INFO:root:Epoch: 0225 val_loss: 2.5428 val_roc: 0.9308 val_ap: 0.9344
INFO:root:Epoch: 0230 lr: 0.01 train_loss: 0.2138 train_roc: 0.9984 train_ap: 0.9964 time: 1.0174s
INFO:root:Epoch: 0230 val_loss: 2.4299 val_roc: 0.9281 val_ap: 0.9335
INFO:root:Epoch: 0235 lr: 0.01 train_loss: 0.2380 train_roc: 0.9974 train_ap: 0.9950 time: 0.9813s
INFO:root:Epoch: 0235 val_loss: 1.8029 val_roc: 0.9244 val_ap: 0.9317
INFO:root:Epoch: 0240 lr: 0.01 train_loss: 0.2151 train_roc: 0.9972 train_ap: 0.9916 time: 0.9956s
INFO:root:Epoch: 0240 val_loss: 1.7815 val_roc: 0.9219 val_ap: 0.9308
INFO:root:Epoch: 0245 lr: 0.01 train_loss: 0.2155 train_roc: 0.9979 train_ap: 0.9957 time: 0.9737s
INFO:root:Epoch: 0245 val_loss: 2.2354 val_roc: 0.9275 val_ap: 0.9357
INFO:root:Epoch: 0250 lr: 0.01 train_loss: 0.2294 train_roc: 0.9978 train_ap: 0.9958 time: 0.9641s
INFO:root:Epoch: 0250 val_loss: 2.5605 val_roc: 0.9300 val_ap: 0.9387
INFO:root:Epoch: 0255 lr: 0.01 train_loss: 0.2145 train_roc: 0.9971 train_ap: 0.9928 time: 0.9650s
INFO:root:Epoch: 0255 val_loss: 2.2361 val_roc: 0.9256 val_ap: 0.9357
INFO:root:Epoch: 0260 lr: 0.01 train_loss: 0.2185 train_roc: 0.9974 train_ap: 0.9927 time: 0.9757s
INFO:root:Epoch: 0260 val_loss: 2.2134 val_roc: 0.9240 val_ap: 0.9348
INFO:root:Epoch: 0265 lr: 0.01 train_loss: 0.2298 train_roc: 0.9979 train_ap: 0.9956 time: 0.9542s
INFO:root:Epoch: 0265 val_loss: 2.2152 val_roc: 0.9226 val_ap: 0.9336
INFO:root:Epoch: 0270 lr: 0.01 train_loss: 0.2190 train_roc: 0.9974 train_ap: 0.9943 time: 0.9595s
INFO:root:Epoch: 0270 val_loss: 2.1556 val_roc: 0.9218 val_ap: 0.9329
INFO:root:Early stopping
INFO:root:Optimization Finished!
INFO:root:Total time elapsed: 423.7334s
INFO:root:Val set results: val_loss: 2.0133 val_roc: 0.9374 val_ap: 0.9431
INFO:root:Test set results: test_loss: 1.8611 test_roc: 0.9354 test_ap: 0.9362
INFO:root:Saved model in /workspace/xiongbo/hgcn/logs/lp/2021_5_2/33
