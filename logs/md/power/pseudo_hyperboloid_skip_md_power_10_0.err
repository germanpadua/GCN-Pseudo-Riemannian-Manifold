INFO:root:Using: cuda:0
INFO:root:Using seed 1234.
INFO:root:MDModel(
  (encoder): HGCN(
    (layers): Sequential(
      (0): HyperbolicGraphConvolution(
        (linear): HypLinear(
          in_features=4942, out_features=10, c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (agg): HypAgg(
          c=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
        (hyp_act): HypAct(
          c_in=Parameter containing:
          tensor([-1.], requires_grad=True), c_out=Parameter containing:
          tensor([-1.], requires_grad=True)
        )
      )
    )
  )
  (decoder): MDDecoder()
)
INFO:root:Total number of parameters: 49432
Traceback (most recent call last):
  File "train.py", line 167, in <module>
    train(args)
  File "train.py", line 111, in train
    embeddings = model.encode(data['features'], data['adj_train_norm'])
  File "/workspace/xiongbo/hgcn/hgcn/models/base_models.py", line 89, in encode
    h = self.encoder.encode(x, adj)
  File "/workspace/xiongbo/hgcn/hgcn/models/encoders.py", line 156, in encode
    hidden = self.layers[0].linear(x_hyp)
  File "/workspace/anaconda3/envs/geo/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/workspace/xiongbo/hgcn/hgcn/layers/hyp_layers.py", line 115, in forward
    res = self.manifold.mobius_matvec(drop_weight, x, self.c, time_dim=time_dim)
  File "/workspace/xiongbo/hgcn/hgcn/manifolds/pseudohyperboloid_sh.py", line 318, in mobius_matvec
    u = self.logmap0(x,beta,time_dim=time_dim)
  File "/workspace/xiongbo/hgcn/hgcn/manifolds/pseudohyperboloid_sh.py", line 162, in logmap0
    tangent_s = torch.clamp(self.logmap_0(sphere,beta, time_dim=time_dim),max=self.max_norm)
  File "/workspace/xiongbo/hgcn/hgcn/manifolds/pseudohyperboloid_sh.py", line 266, in logmap_0
    return self.logmap(origin,y, beta,time_dim=time_dim)
  File "/workspace/xiongbo/hgcn/hgcn/manifolds/pseudohyperboloid_sh.py", line 251, in logmap
    U[positive_log_map] = self.logmap_n(x[positive_log_map], y[positive_log_map], beta, time_dim=time_dim)
RuntimeError: CUDA out of memory. Tried to allocate 94.00 MiB (GPU 0; 39.59 GiB total capacity; 1.75 GiB already allocated; 79.69 MiB free; 1.75 GiB reserved in total by PyTorch)
